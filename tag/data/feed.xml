<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator>
  <link href="http://localhost:4000/tag/data/feed.xml" rel="self" type="application/atom+xml" />
  <link href="http://localhost:4000/" rel="alternate" type="text/html" />
  <updated>2022-02-16T22:55:49+09:00</updated>
  <id>http://localhost:4000/tag/data/feed.xml</id>

  
  
  

  
    <title type="html">Johnâ€™s IT Blog | </title>
  

  
    <subtitle>AI &amp; Frontend Developer</subtitle>
  

  

  
    
      
    
  

  
  

  
    <entry>
      <title type="html">í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 6(ResNet, Residual Learning for Image Recognition)</title>
      <link href="http://localhost:4000/cnn-basic-6" rel="alternate" type="text/html" title="í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 6(ResNet, Residual Learning for Image Recognition)" />
      <published>2022-01-27T21:00:00+09:00</published>
      <updated>2022-01-27T21:00:00+09:00</updated>
      <id>http://localhost:4000/cnn-basic-6</id>
      <content type="html" xml:base="http://localhost:4000/cnn-basic-6">&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;CNN ê°•ì¢ŒëŠ” ì—¬ëŸ¬ ì ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ(CNN, Convolution Neural Network)&lt;/a&gt;&lt;/li&gt; &lt;!-- í™•ì¥ì X ì‹œê°„ X íŒŒì¼ì˜ ì´ë¦„ë§Œ ì‘ì„±--&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-2&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 2(ì—­ì „íŒŒ, Backpropagation)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-3&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 3(ë°°ì¹˜ì •ê·œí™”, Batch Normalization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-4&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 4(ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”, Weight Initialization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-5&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 5(VGGNet, Very Deep Convolutional Network)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-6&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 6(ResNet, Residual Learning for Image Recognition)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;resnet&quot;&gt;ResNet&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;ILSVRC 2015 ìš°ìŠ¹ (3.6% Top 5 Error)í•œ ëª¨ë¸ì´ë©° Deep Residual Learning ì´ë¼ê³ ë„ ë¶€ë¥¸ë‹¤.&lt;/li&gt;
  &lt;li&gt;152ê°œì˜ Layer êµ¬ì¡°ì´ë©° 8ë°° ê¹Šì€ Layersë¥¼ ê°€ì¡ŒìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ì‹¤í–‰ ì‹œê°„ì´ VGGNetë³´ë‹¤ ë¹ ë¥´ë‹¤.&lt;/li&gt;
  &lt;li&gt;ì´ ëª¨ë¸ì€ ì¼ë°˜ì ì¸ ë ˆì´ì–´ë§Œ ê¹Šì€ ëª¨ë¸ë“¤ê³¼ ë¹„êµí–ˆì„ ë•Œ ì„±ëŠ¥ì´ ì¢‹ì„ ë¿ë§Œ ì•„ë‹ˆë¼ í•™ìŠµ ì†ë„ë„ ë” ë¹ ë¥´ë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;introduction&quot;&gt;Introduction&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;VGGNet ë…¼ë¬¸ì—ì„œ CNN ì˜ ë ˆì´ì–´ê°€ ê¹Šì–´ì§ˆìˆ˜ë¡ ì„±ëŠ¥ì´ ë” ì¢‹ë‹¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤.&lt;/li&gt;
  &lt;li&gt;í•˜ì§€ë§Œ ë ˆì´ì–´ê°€ ë„ˆë¬´ ê¹Šì–´ì§€ë©´ Vanishing/Exploding gradient, ê·¸ë¦¬ê³  degradation problem í¬ê²Œ ì´ ë‘ ê°€ì§€ ë¬¸ì œì ì— ë´‰ì°©í•œë‹¤.&lt;/li&gt;
  &lt;li&gt;ìš°ì„  Vanishing/Exploding gradient ê°™ì€ ê²½ìš°ì—ëŠ” ë ˆì´ì–´ ì‚¬ì´ì— batchNorm ì„ ì ìš©í•´ì£¼ë©´ í•´ê²°í•  ìˆ˜ ìˆë‹¤.
&lt;img src=&quot;../../assets/built/images/cnn/22-01-27/2.png&quot; alt=&quot;2&quot; width=&quot;65%&quot; height=&quot;65%&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Degradation Problem ì´ë€ ì •í™•ë„ê°€ ì–´ëŠ ìˆœê°„ë¶€í„° ì •ì²´ë˜ê³  ë ˆì´ì–´ê°€ ë” ê¹Šì–´ì§ˆìˆ˜ë¡ ì„±ëŠ¥ì´ ë” ë‚˜ë¹ ì§€ëŠ” í˜„ìƒì„ ì˜ë¯¸í•œë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ ë…¼ë¬¸ì—ì„œëŠ” Residual Learning ì„ í†µí•´ Degradation Problem ì„ í•´ê²°í•˜ëŠ” ë°©ë²•ì„ ì œì‹œí•œë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-27/3.png&quot; alt=&quot;3&quot; width=&quot;65%&quot; height=&quot;65%&quot; /&gt;
&lt;img src=&quot;../../assets/built/images/cnn/22-01-27/0.png&quot; alt=&quot;0&quot; width=&quot;30%&quot; height=&quot;30%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ê°„ë‹¨í•˜ê²Œ input ì„ x, inputì´ í†µê³¼í•˜ëŠ” Function ì„ F(x), ê·¸ë¦¬ê³  Output ì„ H(x) ì´ë¼ê³  ê°€ì •í•´ë³´ì. F(x) = H(x) - x ë¥¼ ìµœì†Œí™”ì‹œí‚¤ëŠ” Residual mappingìœ¼ë¡œ H(x)ë¥¼ ì¬ì •ì˜í•œë‹¤. &lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;Residual Learning ì—ì„œëŠ” F(x) ë¥¼ H(x) - x ë¼ê³  define í•´ ì£¼ì—ˆë‹¤. ì›ë˜ Output H(x) ì—ì„œ ìê¸° ìì‹ ì¸ x ë¥¼ ë¹¼ì£¼ê¸° ë•Œë¬¸ì— â€˜Residual Learningâ€™ ì´ë¼ëŠ” ì´ë¦„ì„ ê°€ì§€ê²Œ ëœë‹¤. &lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;ë˜ x ê°€ ì´ F(x) ë¥¼ í†µê³¼í•œ ì´í›„ì—, ì´ ê°’ì€ ìê¸° ìì‹ ì¸ x ì™€ ë”í•´ì£¼ê³ , Layerë¥¼ Skipí•´ì„œ ë”í•´ì£¼ê¸°ì— â€˜Skip Connectionsâ€™ ì´ë¼ê³  ë¶€ë¥¸ë‹¤. ì´ Residual Block ì„ í†µê³¼í•˜ê³  ë‚˜ë©´ ìµœì¢…ì ì¸ ê°’ì€ F(x) + x ê°€ ë‚˜ì˜¤ê²Œ ëœë‹¤.&lt;/li&gt;
  &lt;li&gt;F(x) ì™€ x ë¥¼ ì§ì ‘ì ìœ¼ë¡œ ë”í•´ì£¼ê¸° ìœ„í•´ì„  F(x) ì™€ x ê°€ ì„œë¡œ ê°™ì€ Dimension ì´ì–´ì•¼ í•œë‹¤. ì¼ë°˜ì ìœ¼ë¡œ F(x) ì™€ ì´ì „ì˜ input xê°€ ì±„ë„ìˆ˜ê°€ ê°™ë‹¤ë©´ ë³„ë‹¤ë¥¸ ì¡°ì¹˜ë¥¼ ì·¨í•´ì£¼ì§€ ì•Šì•„ë„ ê·¸ëƒ¥ ë”í•´ì£¼ë©´ ëœë‹¤.&lt;/li&gt;
  &lt;li&gt;í•˜ì§€ë§Œ Channel ê°œìˆ˜ê°€ ë‹¬ë¼ì§€ê±°ë‚˜ MaxPool ë“±ì— ì˜í•´ì„œ x ì˜ í¬ê¸°ê°€ ë‹¬ë¼ì§ˆ ë•Œ, padding ì´ë‚˜ ë³„ë‹¤ë¥¸ Ws ë¥¼ ê³±í•´ì£¼ì–´ì„œ ì‚¬ì´ì¦ˆë¥¼ ë§¤ì¹­ ì‹œì¼œì£¼ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;resnet-architecture&quot;&gt;ResNet Architecture&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-27/4.png&quot; alt=&quot;4&quot; width=&quot;65%&quot; height=&quot;65%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ResNet ì˜ ê¸°ë³¸ êµ¬ì¡°ëŠ” VGGNet-34 ì„ ë”°ë¥¸ë‹¤. ìœ„ ê·¸ë¦¼ì„ ë³´ë©´ VGG-34 ê³¼ ëª¨ë¸ êµ¬ì„±ì€ ê°™ì€ë°, ë ˆì´ì–´ ë‘ê°œë§ˆë‹¤ Skip Connection ì„ í•´ì¤€ë‹¤ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.&lt;/li&gt;
  &lt;li&gt;ì¤‘ê°„ì— ì ì„ ìœ¼ë¡œ í‘œì‹œëœ Skip Connection ì€ x ì™€ F(x) ì˜ Dimension ì´ ë‹¬ë¼ì ¸ì„œ ë”°ë¡œ ë§ì¶°ì¤˜ì•¼ ë˜ëŠ” Skip Connection ë“¤ì„ ì˜ë¯¸í•œë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;deeper-bottleneck-architectures&quot;&gt;Deeper Bottleneck Architectures&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-27/7.png&quot; alt=&quot;7&quot; width=&quot;65%&quot; height=&quot;65%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ë„¤íŠ¸ì›Œí¬ì˜ ê¹Šì´ê°€ 50 ì„ ë„˜ì–´ê°€ë©´, ì œì•„ë¬´ë¦¬ ResNetì„ ì´ìš©í•˜ê³  3x3 í•„í„°ë§Œ ì‚¬ìš©í•œë‹¤ í• ì§€ë¼ë„ Training ì‹œê°„ì´ ë§¤ìš° ê¸¸ì–´ì§ˆ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ì´ ê²½ìš°ì—” ì›ë˜ ëª¨ë¸ êµ¬ì¡°ì—ì„œ ì•½ê°„ì˜ ìˆ˜ì •ì´ í•„ìš”í•˜ë‹¤.&lt;/li&gt;
  &lt;li&gt;3x3 í•„í„°ë¥¼ ë‘ ë²ˆ ì‚¬ìš©í•˜ëŠ” ëŒ€ì‹ , 1x1 -&amp;gt; 3x3 -&amp;gt; 1x1 í•„í„°ë“¤ì„ ì‚¬ìš©í•˜ëŠ” êµ¬ì¡°ë¥¼ ë§Œë“ ë‹¤. ì´ë ‡ê²Œ ìˆ˜ì •í•œ êµ¬ì¡°ëŠ” Dimension ì˜ í¬ê¸°ë¥¼ ì¤„ì¼ ë¿ë§Œ ì•„ë‹ˆë¼ ì‹œê°„ ë³µì¡ë„ë„ ì¤„ì´ëŠ” íš¨ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;experiments&quot;&gt;Experiments&lt;/h3&gt;
&lt;p&gt;ResNet ì€ 1000ê°œì˜ í´ë¼ìŠ¤ë¡œ ì´ë£¨ì–´ì§„ ImageNet 2012 ë°ì´í„°ì…‹ìœ¼ë¡œ training
&lt;img src=&quot;../../assets/built/images/cnn/22-01-27/5.png&quot; alt=&quot;5&quot; width=&quot;65%&quot; height=&quot;65%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ìœ„ ê·¸ë˜í”„ì—ì„œ ì™¼ìª½ ê·¸ë¦¼ì€ Plain Network ì˜ 18, 34 Layer, ì˜¤ë¥¸ìª½ ê·¸ë¦¼ì€ ResNet ì˜ 18, 34 layer ì˜ Loss ê³¼ì •ì´ë‹¤.&lt;/li&gt;
  &lt;li&gt;ìš°ì„  ì™¼ìª½ ê·¸ë¦¼ì—ì„œëŠ” Degradation Problem ì´ ë³´ì´ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. 34-Layer ë„¤íŠ¸ì›Œí¬ê°€ 18-layer ë³´ë‹¤ Loss ê°€ ë†’ê¸° ë•Œë¬¸ì´ë‹¤.&lt;/li&gt;
  &lt;li&gt;ë°˜ë©´ ResNet ê°™ì€ ê²½ìš°ì—” 34-Layer ê°€ Loss ê°€ ë” ë‚®ê²Œ ë‚˜ì˜¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. Degradation Problem ì´ í•´ê²°ëìŒì„ ë³´ì—¬ì£¼ëŠ” ê·¸ë˜í”„ì´ë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-27/6.png&quot; alt=&quot;6&quot; width=&quot;65%&quot; height=&quot;65%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ìœ„ í‘œì—ì„œëŠ” ë” ê¹Šì€ ResNet ë“¤ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì¤€ë‹¤. ë ˆì´ì–´ê°€ ê¹Šì–´ì§€ë©´ ê¹Šì–´ì§ˆìˆ˜ë¡ error ëŠ” ì¤„ì–´ë“œëŠ” ê²½í–¥ì„±ì„ ë³¼ ìˆ˜ ìˆê³ , 110 ê°œì˜ ë ˆì´ì–´ê°€ ìˆì„ ë•Œ ê°€ì¥ ì ì€ ì—ëŸ¬ê°€ ë‚˜ì˜¨ë‹¤.&lt;/li&gt;
  &lt;li&gt;í•˜ì§€ë§Œ ê·¸ë ‡ë‹¤ê³  ë„ˆë¬´ ê¹Šì–´ì§€ë©´, ì˜ˆë¥¼ ë“¤ì–´ 1000 ê°œ ì´ìƒì˜ ë ˆì´ì–´ê°€ ì¡´ì¬í•  ë•ŒëŠ” ì˜¤ë²„í”¼íŒ…ìœ¼ë¡œ ì¸í•˜ì—¬ ì„±ëŠ¥ì´ ë” ì–•ì€ ëª¨ë¸ë“¤ë³´ë‹¤ ë” ì•ˆ ì¢‹ê²Œ ë‚˜ì˜¨ë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;p&gt;ì°¸ì¡° ë¬¸í—Œ&lt;br /&gt;
[1] He, K., Zhang, X., Ren, S., &amp;amp; Sun, J. (2016). Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 770-778).&lt;br /&gt;
&lt;a href=&quot;https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf&quot;&gt;https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf&lt;/a&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>John</name>
        
        
      </author>

      

      
        <category term="data" />
      

      
        <summary type="html">CNN ê°•ì¢ŒëŠ” ì—¬ëŸ¬ ì ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ(CNN, Convolution Neural Network) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 2(ì—­ì „íŒŒ, Backpropagation) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 3(ë°°ì¹˜ì •ê·œí™”, Batch Normalization) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 4(ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”, Weight Initialization) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 5(VGGNet, Very Deep Convolutional Network) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 6(ResNet, Residual Learning for Image Recognition)</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 5(VGGNet, Very Deep Convolutional Network)</title>
      <link href="http://localhost:4000/cnn-basic-5" rel="alternate" type="text/html" title="í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 5(VGGNet, Very Deep Convolutional Network)" />
      <published>2022-01-23T21:00:00+09:00</published>
      <updated>2022-01-23T21:00:00+09:00</updated>
      <id>http://localhost:4000/cnn-basic-5</id>
      <content type="html" xml:base="http://localhost:4000/cnn-basic-5">&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;CNN ê°•ì¢ŒëŠ” ì—¬ëŸ¬ ì ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ(CNN, Convolution Neural Network)&lt;/a&gt;&lt;/li&gt; &lt;!-- í™•ì¥ì X ì‹œê°„ X íŒŒì¼ì˜ ì´ë¦„ë§Œ ì‘ì„±--&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-2&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 2(ì—­ì „íŒŒ, Backpropagation)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-3&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 3(ë°°ì¹˜ì •ê·œí™”, Batch Normalization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-4&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 4(ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”, Weight Initialization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-5&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 5(VGGNet, Very Deep Convolutional Network)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-6&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 6(ResNet, Residual Learning for Image Recognition)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;vggnet&quot;&gt;VGGNet&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;ILSVRC 2014 ëŒ€íšŒì—ì„œ 2ë“±ì„ ì°¨ì§€í•œ Karen Simonyanê³¼ Andrew Zissermanì´ ë§Œë“  CNN ëª¨ë¸&lt;/li&gt;
  &lt;li&gt;ILSVRCëŠ” ImageNet Large Scale Visual Recognition Challengeì˜ ì•½ìë¡œ, 2010ë…„ì— ì‹œì‘ëœ ì´ë¯¸ì§€ ì¸ì‹(Image Recognition) ê²½ì§„ëŒ€íšŒ&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;vgg-16-architecture&quot;&gt;VGG-16 Architecture&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-23/vggnet_2.jpeg&quot; alt=&quot;1&quot; width=&quot;65%&quot; height=&quot;65%&quot; /&gt;
&lt;img src=&quot;../../assets/built/images/cnn/22-01-23/vggnet_1.png&quot; alt=&quot;0&quot; width=&quot;65%&quot; height=&quot;65%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;13 Convolution Layers + 3 Fully-connected Layers&lt;/li&gt;
  &lt;li&gt;3x3 convolution filters&lt;/li&gt;
  &lt;li&gt;stride: 1 &amp;amp; padding: 1&lt;/li&gt;
  &lt;li&gt;2x2 max pooling (stride : 2)&lt;/li&gt;
  &lt;li&gt;ReLU&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;configuration&quot;&gt;Configuration&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-23/vggnet_4.jpeg&quot; alt=&quot;4&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Input Size RGB 224x224, ë³µìˆ˜ì˜ Convolution layer, Max-Poolingì¸µì´ ë°˜ë³µë˜ëŠ” êµ¬ì¡°ì´ë©° ìµœì¢…ë‹¨ì—ëŠ” FC layerìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3x3-í•„í„°-ì‚¬ìš©-why-use-smaller-filters&quot;&gt;3x3 í•„í„° ì‚¬ìš© (Why use smaller filters?)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;VGG ëª¨ë¸ ì´ì „ Convolutional Networkë¥¼ í™œìš©í•˜ì—¬ ì´ë¯¸ì§€ ë¶„ë¥˜ì—ì„œ ì¢‹ì€ ì„±ê³¼ë¥¼ ë³´ì˜€ë˜ ëª¨ë¸ë“¤ì€ ë¹„êµì  í° Receptive Fieldë¥¼ ê°–ëŠ” 11x11í•„í„°ë‚˜ 7x7 í•„í„°ë¥¼ í¬í•¨&lt;/li&gt;
  &lt;li&gt;ê·¸ëŸ¬ë‚˜ VGG ëª¨ë¸ì€ ì˜¤ì§ 3x3 í¬ê¸°ì˜ ì‘ì€ í•„í„°ë§Œ ì‚¬ìš©í–ˆìŒì—ë„ ì´ë¯¸ì§€ ë¶„ë¥˜ ì •í™•ë„ë¥¼ ë¹„ì•½ì ìœ¼ë¡œ ê°œì„ 
&lt;img src=&quot;../../assets/built/images/cnn/22-01-23/vggnet_3.png&quot; alt=&quot;3&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;u&gt;íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ì¤„ì´ê³  Layerë¥¼ ë‹¤ì¸µ ìŒ“ì•„ì„œ ëª¨ë¸ì˜ ì „ì²´ Depthë¥¼ ê¹Šê²Œ ë§Œë“¤ê¸° ìœ„í•´ì„œì´ë‹¤.&lt;/u&gt;&lt;/li&gt;
  &lt;li&gt;Input Sizeê°€ 7x7ì´ë©°, 3x3ì˜ Output Sizeë¥¼ ë„ì¶œí•´ë‚´ì•¼ í•œë‹¤ê³  ê°€ì •í•˜ì, ì´ë•Œ Filter Sizeê°€ 3x3ì´ë¼ë©´ ì´ ë‘ ì°¨ë¡€ì˜ Convolutionì„ ì§„í–‰í•´ì•¼ í•œë‹¤.&lt;/li&gt;
  &lt;li&gt;ë°˜ë©´ 5x5ì˜ Filter Sizeë¡œëŠ” ë‹¨ í•œ ë²ˆì˜ Convolutionìœ¼ë¡œ ë™ì¼í•œ ì‚¬ì´ì¦ˆì˜ Feature Mapì„ ì‚°ì¶œí•œë‹¤. 3x3 Filterë¡œ ì„¸ ì°¨ë¡€ Convolution í•˜ëŠ” ê²ƒì€ 7x7 Filterë¡œ í•œ ë²ˆ Convolution í•˜ëŠ” ê²ƒê³¼ ëŒ€ì‘ëœë‹¤.&lt;/li&gt;
  &lt;li&gt;ì¦‰, 3x3 Filter 3ê°œëŠ” 7x7 Filter í•˜ë‚˜ì™€ ë™ì¼í•œ Receptive Field (= Filterê°€ í•œ ë²ˆì— ë³¼ ìˆ˜ ìˆëŠ” ì…ë ¥ ì´ë¯¸ì§€ì˜ Spatial Area) ë¥¼ ê°€ì§€ë©´ì„œë„ ë” ê¹Šì€ ë ˆì´ì–´ë¥¼ ìŒ“ì„ ìˆ˜ ìˆê²Œ í•˜ëŠ” ê²ƒì´ë‹¤.&lt;/li&gt;
  &lt;li&gt;ì´ì²˜ëŸ¼ Layer ìˆ˜ê°€ ëŠ˜ì–´ë‚˜ë©´ ì´ë¯¸ì§€ íŠ¹ì„±ì— ë¹„ì„ í˜•ì„±ì„ ë” ì¶”ê°€í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—(Deeper, more non-linearities), Filterë¥¼ í†µí•´ ì¶”ì¶œí•œ Featureê°€ ì ì  ìœ ìš©í•´ì§€ëŠ” ì´ì ì„ ì–»ê²Œ ëœë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;í•„í„°ì˜-í¬ê¸°ê°€-ì‘ìœ¼ë©´-íŒŒë¼ë¯¸í„°-ìˆ˜ë„-ì ì–´ì§„ë‹¤smaller-filters-fewer-parameters&quot;&gt;í•„í„°ì˜ í¬ê¸°ê°€ ì‘ìœ¼ë©´ íŒŒë¼ë¯¸í„° ìˆ˜ë„ ì ì–´ì§„ë‹¤(Smaller filters, fewer parameters)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;3x3 Filterì—ëŠ” 9ê°œì˜ íŒŒë¼ë¯¸í„°ê°€ ìˆë‹¤. ì´ë•Œ Depthë¥¼ Cë¼ê³  í•œë‹¤ë©´ 3 x 3 x C ê°œì˜ íŒŒë¼ë¯¸í„°ê°€ ìˆê³ , ì—¬ê¸°ì— ì¶œë ¥ë˜ëŠ” Feature Mapì˜ ê°œìˆ˜(=ì…ë ¥ Depth)ë¥¼ ê³±í•˜ë©´ ê° ë ˆì´ì–´ ë‹¹ 3x3xCxCì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§€ê²Œ ëœë‹¤. ë§Œì•½ Layerê°€ 3ê°œë¼ë©´, ì´ íŒŒë¼ë¯¸í„°ëŠ” 3 * (32C2)ê°œì´ë‹¤.&lt;/li&gt;
  &lt;li&gt;ë°˜ë©´ 7x7 Filterì˜ ê²½ìš° 7x7xCxCê°œì˜ íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ìˆì„ ê²ƒì´ë‹¤. ë ˆì´ì–´ë¥¼ ë” ì ê²Œ ìŒ“ì•˜ìŒì—ë„ íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ë§ì€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.&lt;/li&gt;
  &lt;li&gt;ì—¬ê¸°ì„œ íŒŒë¼ë¯¸í„°(weight) ìˆ˜ê°€ ì ë‹¤ëŠ” ê²ƒì€ ì–´ë–¤ ì˜ë¯¸ë¥¼ ê°€ì§ˆê¹Œ? CNNì—ì„œ ê°€ì¤‘ì¹˜ëŠ” ëª¨ë‘ í›ˆë ¨ì´ í•„ìš”í•œ ê²ƒë“¤ì´ë¯€ë¡œ, &lt;u&gt;íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ì ì„ ìˆ˜ë¡ í•™ìŠµ ì†ë„ê°€ ë¹¨ë¼ì§„ë‹¤ëŠ” ì´ì ì„ ì–»ì„ ìˆ˜ ìˆë‹¤.&lt;/u&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ê²°ë¡ &quot;&gt;ê²°ë¡ &lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;VGGNetì€ 3x3ì˜ ì‘ì€ í•„í„°ë¥¼ ëª¨ë“  Conv ë ˆì´ì–´ì— ì‚¬ìš©í•˜ì˜€ë‹¤.&lt;/li&gt;
  &lt;li&gt;ì‘ì€ í•„í„°ë¥¼ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ ë” ë§ì€ ReLUí•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆê³  ë” ë§ì€ ë¹„ì„ í˜•ì„±ì„ í™•ë³´í•  ìˆ˜ ìˆì—ˆë‹¤.&lt;/li&gt;
  &lt;li&gt;VGGNetì˜ A~Eê¹Œì§€ ê°ê°ì˜ ë‹¤ë¥¸ ëª¨ë¸ì´ ì•„ë‹ˆë¼ í•™ìŠµì˜ ë‹¨ê³„ë¶€í„° ì•Œ ìˆ˜ ìˆë“¯, ì—…ê·¸ë ˆì´ë“œëœ ëª¨ë¸ì´ë‹¤.&lt;/li&gt;
  &lt;li&gt;ìœ„ì™€ ê°™ì€ íŠ¹ì§•ë“¤ë¡œ AlexNetë³´ë‹¤ 2ë°° ì´ìƒ ê¹Šì€ ë„¤íŠ¸ì›Œí¬ì´ë©° ì¢‹ì€ ì„±ëŠ¥ì„ ê°€ì§„ ëª¨ë¸ì„ ë§Œë“¤ì–´ ë‚¼ ìˆ˜ ìˆì—ˆë‹¤.&lt;/li&gt;
  &lt;li&gt;ì¤„ì˜€ìŒì—ë„ íŒŒë¼ë¯¸í„°ì˜ ìˆ˜ê°€ ì—„ì²­ë‚˜ê²Œ ë§ê¸° ë•Œë¬¸ì— í•™ìŠµ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦°ë‹¤&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
&lt;p&gt;ì°¸ì¡° ë¬¸í—Œ&lt;br /&gt;
&lt;a href=&quot;https://arxiv.org/pdf/1409.1556.pdf&quot;&gt;https://arxiv.org/pdf/1409.1556.pdf&lt;/a&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>John</name>
        
        
      </author>

      

      
        <category term="data" />
      

      
        <summary type="html">CNN ê°•ì¢ŒëŠ” ì—¬ëŸ¬ ì ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ(CNN, Convolution Neural Network) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 2(ì—­ì „íŒŒ, Backpropagation) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 3(ë°°ì¹˜ì •ê·œí™”, Batch Normalization) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 4(ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”, Weight Initialization) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 5(VGGNet, Very Deep Convolutional Network) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 6(ResNet, Residual Learning for Image Recognition)</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 4(ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”, Weight Initialization)</title>
      <link href="http://localhost:4000/cnn-basic-4" rel="alternate" type="text/html" title="í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 4(ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”, Weight Initialization)" />
      <published>2022-01-17T21:00:00+09:00</published>
      <updated>2022-01-17T21:00:00+09:00</updated>
      <id>http://localhost:4000/cnn-basic-4</id>
      <content type="html" xml:base="http://localhost:4000/cnn-basic-4">&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;CNN ê°•ì¢ŒëŠ” ì—¬ëŸ¬ ì ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ(CNN, Convolution Neural Network)&lt;/a&gt;&lt;/li&gt; &lt;!-- í™•ì¥ì X ì‹œê°„ X íŒŒì¼ì˜ ì´ë¦„ë§Œ ì‘ì„±--&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-2&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 2(ì—­ì „íŒŒ, Backpropagation)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-3&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 3(ë°°ì¹˜ì •ê·œí™”, Batch Normalization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-4&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 4(ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”, Weight Initialization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-5&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 5(VGGNet, Very Deep Convolutional Network)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-6&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 6(ResNet, Residual Learning for Image Recognition)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ê°€ì¤‘ì¹˜-ì´ˆê¸°í™”&quot;&gt;ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”&lt;/h3&gt;
&lt;p&gt;&lt;br /&gt;
&lt;strong&gt;ê°€ì¤‘ì¹˜ê°€ ì¤‘ìš”í•œ ì´ìœ &lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Overfitting-Underfitting ë¬¸ì œê°€ ë°œìƒí•´ ì œëŒ€ë¡œ í•™ìŠµì´ ë˜ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤.&lt;/li&gt;
  &lt;li&gt;ê·¸ë˜ë””ì–¸íŠ¸ ì†ì‹¤(Vanishing Gradient)ì™€ í­ì£¼(Exploding)ë¬¸ì œê°€ ë°œìƒí•œë‹¤.&lt;/li&gt;
  &lt;li&gt;ì§€ì—­ ìµœì í™”(Local Optimization)ì— ì‹¤íŒ¨í•´ Local mnimumì— ìˆ˜ë ´í•˜ê¸°ë„ í•œë‹¤.&lt;/li&gt;
  &lt;li&gt;ì¦‰, ê°™ì€ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ë”ë¼ë„ ê°€ì¤‘ì¹˜ê°€ ì–´ë–¤ ì´ˆê¸° ê°’ì„ ê°–ëŠëƒì— ë”°ë¼ì„œ ëª¨ë¸ í›ˆë ¨ ê²°ê³¼ê°€ ë‹¬ë¼ì§„ë‹¤.
&lt;img src=&quot;../../assets/built/images/cnn/22-01-18/0.png&quot; alt=&quot;0&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;ê°€ì¤‘ì¹˜ ê°’ì´ 0ì¼ ê²½ìš°, í•™ìŠµì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤.&lt;/li&gt;
  &lt;li&gt;ê°€ì¤‘ì¹˜ ê°’ì„ ê°™ì€ ê°’ìœ¼ë¡œ í•  ê²½ìš°, 1ê°œ ì‹ ê²½ë§ì— í•™ìŠµì‹œí‚¤ëŠ” ê²ƒê³¼ ë™ì¼&lt;/li&gt;
  &lt;li&gt;í‰ê·  0 ,1ë³´ë‹¤ ì‘ì€ í‘œì¤€í¸ì°¨ ë¶„í¬ë¥¼ ì‚¬ìš©í•œë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;1) Sigmoid, ì •ê·œë¶„í¬&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-18/4.png&quot; alt=&quot;4&quot; width=&quot;70%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;í‘œì¤€í¸ì°¨ê°€ í¬ê¸° ë•Œë¬¸ì— í•™ìŠµì´ ë°˜ë³µë  ìˆ˜ë¡ 0,1ë¡œ ì¹˜ìš°ì¹˜ëŠ” ë¬¸ì œê°€ ë°œìƒ&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2) 1)ì—ì„œ í‘œì¤€í¸ì°¨ë¥¼ ì¤„ì˜€ì„ ê²½ìš°&lt;/strong&gt;
&lt;img src=&quot;../../assets/built/images/cnn/22-01-18/5.png&quot; alt=&quot;5&quot; width=&quot;70%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Sigmoid ê·¸ë˜ë””ì–¸íŠ¸ ìµœëŒ“ê°’ì´ 0.25ì´ë¯€ë¡œ í˜„ìƒì„ ì™„í™”í•  ìˆ˜ëŠ” ìˆì§€ë§Œ 0.5ë¡œ ëª°ë¦¬ëŠ” í˜„ìƒ&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;â€œë” ë‚˜ì€ ë°©ë²•ì„ ì°¾ì•„ë³´ìâ€&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;LeCun Initialization&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;CNN LeNet ì°½ì‹œì LeCunì´ ë„ì…&lt;/li&gt;
  &lt;li&gt;ì •ê·œë¶„í¬, Uniform ë¶„í¬ë¥¼ ë”°ë¥´ëŠ” ë°©ë²• 2ê°€ì§€ê°€ ìˆë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-18/6.png&quot; alt=&quot;6&quot; width=&quot;70%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Xavier Initialization&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ì´ì „ ë…¸ë“œì™€ ë‹¤ìŒ ë…¸ë“œ ê°œìˆ˜ì— ì˜ì¡´í•˜ëŠ” ë°©ë²•&lt;/li&gt;
  &lt;li&gt;ë¹„ì„ í˜•í•¨ìˆ˜(ex. sigmoid, tanh)ì—ì„œ íš¨ê³¼ì ì¸ ê²°ê³¼&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-18/7.png&quot; alt=&quot;7&quot; width=&quot;70%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;He Initialization&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Relu í™œì„±í™” í•¨ìˆ˜ ì‚¬ìš©ì‹œ, Xavier ì„¤ì •ì´ ë¹„íš¨ìœ¨ì ì¸ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¨ë‹¤.(í‰ê· , í‘œì¤€í¸ì°¨ 0ìœ¼ë¡œ ìˆ˜ë ´)&lt;/li&gt;
  &lt;li&gt;ìµœê·¼ ëŒ€ë¶€ë¶„ ëª¨ë¸ì—ì„œ He ì´ˆê¸°í™”ë¥¼ ì‚¬ìš©í•œë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-18/8.png&quot; alt=&quot;8&quot; width=&quot;70%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;â­ï¸ ìµœê·¼ Deep CNN ëª¨ë¸ë“¤ì€ &lt;span style=&quot;color:#2D3748; background-color:#fff5b1;&quot;&gt;Gaussian Distribution&lt;/span&gt; ì´ˆê¸°í™” ë°©ë²• ì‚¬ìš©&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;ì°¸ì¡° ë¬¸í—Œ
&lt;a href=&quot;https://kharshit.github.io/blog/2018/12/28/why-batch-normalization&quot;&gt;https://kharshit.github.io/blog/2018/12/28/why-batch-normalization&lt;/a&gt;
&lt;a href=&quot;https://reniew.github.io/13/&quot;&gt;https://reniew.github.io/13/&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://wooono.tistory.com/227&quot;&gt;https://wooono.tistory.com/227&lt;/a&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>John</name>
        
        
      </author>

      

      
        <category term="data" />
      

      
        <summary type="html">CNN ê°•ì¢ŒëŠ” ì—¬ëŸ¬ ì ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ(CNN, Convolution Neural Network) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 2(ì—­ì „íŒŒ, Backpropagation) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 3(ë°°ì¹˜ì •ê·œí™”, Batch Normalization) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 4(ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”, Weight Initialization) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 5(VGGNet, Very Deep Convolutional Network) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 6(ResNet, Residual Learning for Image Recognition)</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 3(ë°°ì¹˜ì •ê·œí™”, Batch Normalization)</title>
      <link href="http://localhost:4000/cnn-basic-3" rel="alternate" type="text/html" title="í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 3(ë°°ì¹˜ì •ê·œí™”, Batch Normalization)" />
      <published>2022-01-17T21:00:00+09:00</published>
      <updated>2022-01-17T21:00:00+09:00</updated>
      <id>http://localhost:4000/cnn-basic-3</id>
      <content type="html" xml:base="http://localhost:4000/cnn-basic-3">&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;CNN ê°•ì¢ŒëŠ” ì—¬ëŸ¬ ì ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ(CNN, Convolution Neural Network)&lt;/a&gt;&lt;/li&gt; &lt;!-- í™•ì¥ì X ì‹œê°„ X íŒŒì¼ì˜ ì´ë¦„ë§Œ ì‘ì„±--&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-2&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 2(ì—­ì „íŒŒ, Backpropagation)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-3&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 3(ë°°ì¹˜ì •ê·œí™”, Batch Normalization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-4&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 4(ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”, Weight Initialization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-5&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 5(VGGNet, Very Deep Convolutional Network)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-6&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 6(ResNet, Residual Learning for Image Recognition)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ë°°ì¹˜-ì •ê·œí™”&quot;&gt;ë°°ì¹˜ ì •ê·œí™”&lt;/h3&gt;
&lt;p&gt;ê¹Šì€ ì‹ ê²½ë§ì¼ ìˆ˜ë¡ ê°™ì€ Input ì´ë¼ë„ ê°€ì¤‘ì¹˜ê°€ ì¡°ê¸ˆì´ë¼ë„ ë‹¤ë¥´ë‹¤ë©´ ì™„ì „íˆ ë‹¤ë¥¸ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;â€œê° ì¸µì´ í™œì„±í™”ë¥¼ ì ë‹¹íˆ í¼ëœ¨ë¦¬ë„ë¡ ê°•ì œë¡œ í•´ë³´ìâ€&lt;/strong&gt;
&lt;img src=&quot;../../assets/built/images/cnn/22-01-18/1.jpeg&quot; alt=&quot;1&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;ë°°ì¹˜ë€?&lt;/strong&gt; ì‹ ê²½ë§ í•™ìŠµì‹œ, ì „ì²´ ë°ì´í„°ë¥¼ í•œ ë²ˆì— í•™ìŠµì‹œí‚¤ì§€ ì•Šê³ , ì¡°ê·¸ë§Œ ë‹¨ìœ„ë¡œ ë¶„í• í•´ì„œ í•™ìŠµ ì‹œí‚¤ëŠ” ê²ƒ.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ë°°ì¹˜ ì •ê·œí™”ë€?&lt;/strong&gt; ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì •ê·œí™” í•˜ëŠ” ê²ƒ.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;[ë°°ì¹˜ ì •ê·œí™” ì•Œê³ ë¦¬ì¦˜]&lt;/strong&gt;
&lt;img src=&quot;../../assets/built/images/cnn/22-01-18/2.png&quot; alt=&quot;2&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ì—¡ì‹¤ë¡ ì€ ë¶„ëª¨ê°€ 0 ì´ ë˜ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•œ ì•„ì£¼ ì‘ì€ ìˆ«ì(1e-5~7)&lt;/li&gt;
  &lt;li&gt;ì •ê·œí™” ì´í›„, ë°°ì¹˜ ë°ì´í„°ë“¤ì„ scale(ê°ë§ˆ(Î³)), shift(ë² íƒ€(Î²)) ë¥¼ í†µí•´ ìƒˆë¡œìš´ ê°’ìœ¼ë¡œ ë°”ê¾¼ë‹¤.&lt;/li&gt;
  &lt;li&gt;ë°ì´í„°ë¥¼ ê³„ì† ì •ê·œí™” í•˜ê²Œ ë˜ë©´, í™œì„±í™” í•¨ìˆ˜ì˜ ë¹„ì„ í˜• ì„±ì§ˆì„ ìƒê²Œ ë˜ëŠ” ë¬¸ì œ ë°œìƒ&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ì´ Sigmoid í•¨ìˆ˜ ê²½ìš°, ì…ë ¥ ê°’ì´ N(0, 1) ì´ë¼ë©´, 95% ì˜ ì…ë ¥ ê°’ì€ Sigmoid í•¨ìˆ˜ ê·¸ë˜í”„ì˜ ì¤‘ê°„ (x = (-1.96, 1.96) êµ¬ê°„)ì— ì†í•˜ê²Œ ëœë‹¤.
&lt;img src=&quot;../../assets/built/images/cnn/22-01-18/3.png&quot; alt=&quot;3&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;ê°ë§ˆ(Î³), ë² íƒ€(Î²)ë¥¼ í†µí•´ í™œì„±í•¨ìˆ˜ë¡œ ë“¤ì–´ê°€ëŠ” ê°’ì˜ ë²”ìœ„ë¥¼ ë³€í™˜í•˜ì—¬ ë¹„ì„ í˜• ì„±ì§ˆì„ ë³´ì¡´&lt;/li&gt;
  &lt;li&gt;ê°ë§ˆ(Î³), ë² íƒ€(Î²) ê°’ì€ í•™ìŠµ ê°€ëŠ¥í•œ ë³€ìˆ˜, ì—­ì „íŒŒë¥¼ í†µí•´ì„œ í•™ìŠµ&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;â­&lt;strong&gt;ë°°ì¹˜ ì •ê·œí™” íš¨ê³¼&lt;/strong&gt;â­&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;í•™ìŠµì´ ë¹ ë¥´ê²Œ ì§„í–‰(Epoch ìˆ˜ë¥¼ ì¤„ì´ëŠ”ë° íš¨ê³¼ì )&lt;/li&gt;
  &lt;li&gt;Dropout í•„ìš”ì„± ê°ì†Œ&lt;/li&gt;
  &lt;li&gt;ë” ë†’ì€ Learning rate ì‚¬ìš© ê°€ëŠ¥&lt;/li&gt;
  &lt;li&gt;ê·œì œ íš¨ê³¼ (ê³¼ì í•© ë°©ì§€)&lt;/li&gt;
  &lt;li&gt;ê·¸ë˜ë””ì–¸íŠ¸ ì†ì‹¤(Vanishing Gradient)ì™€ í­ì£¼(Exploding)ë¬¸ì œ í•´ê²°&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
&lt;p&gt;ì°¸ì¡° ë¬¸í—Œ
&lt;a href=&quot;https://kharshit.github.io/blog/2018/12/28/why-batch-normalization&quot;&gt;https://kharshit.github.io/blog/2018/12/28/why-batch-normalization&lt;/a&gt;
&lt;a href=&quot;https://reniew.github.io/13/&quot;&gt;https://reniew.github.io/13/&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://wooono.tistory.com/227&quot;&gt;https://wooono.tistory.com/227&lt;/a&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>John</name>
        
        
      </author>

      

      
        <category term="data" />
      

      
        <summary type="html">CNN ê°•ì¢ŒëŠ” ì—¬ëŸ¬ ì ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ(CNN, Convolution Neural Network) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 2(ì—­ì „íŒŒ, Backpropagation) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 3(ë°°ì¹˜ì •ê·œí™”, Batch Normalization) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 4(ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”, Weight Initialization) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 5(VGGNet, Very Deep Convolutional Network) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 6(ResNet, Residual Learning for Image Recognition)</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 2(CNN, ì—­ì „íŒŒ Backpropagation)</title>
      <link href="http://localhost:4000/cnn-basic-2" rel="alternate" type="text/html" title="í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 2(CNN, ì—­ì „íŒŒ Backpropagation)" />
      <published>2022-01-17T21:00:00+09:00</published>
      <updated>2022-01-17T21:00:00+09:00</updated>
      <id>http://localhost:4000/cnn-basic-2</id>
      <content type="html" xml:base="http://localhost:4000/cnn-basic-2">&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;CNN ê°•ì¢ŒëŠ” ì—¬ëŸ¬ ì ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ(CNN, Convolution Neural Network)&lt;/a&gt;&lt;/li&gt; &lt;!-- í™•ì¥ì X ì‹œê°„ X íŒŒì¼ì˜ ì´ë¦„ë§Œ ì‘ì„±--&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-2&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 2(ì—­ì „íŒŒ, Backpropagation)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-3&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 3(ë°°ì¹˜ì •ê·œí™”, Batch Normalization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-4&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 4(ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”, Weight Initialization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-5&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 5(VGGNet, Very Deep Convolutional Network)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-6&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 6(ResNet, Residual Learning for Image Recognition)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;cnn-foward-pass&quot;&gt;CNN foward pass&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/1.gif&quot; alt=&quot;1&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;CNNì€ í•„í„°ê°€ ì…ë ¥ë°ì´í„°ë¥¼ ìŠ¬ë¼ì´ë”©í•˜ë©´ì„œ ì§€ì—­ì  íŠ¹ì§•(feature)ì„ ì¶”ì¶œ&lt;/li&gt;
  &lt;li&gt;ì´ íŠ¹ì§•ì„ ìµœëŒ€ê°’(Max Pooling)ì´ë‚˜ í‰ê· ê°’(Average Pooling)ìœ¼ë¡œ ì••ì¶•í•´ ë‹¤ìŒ ë ˆì´ì–´ë¡œ ì „ë‹¬&lt;/li&gt;
  &lt;li&gt;ì´ëŸ° ê³¼ì •ì„ ë°˜ë³µí•´ ë¶„ë¥˜ ë“± ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” ê²ƒì´ CNNì˜ ì¼ë°˜ì ì¸ êµ¬ì¡°&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[Cross-Correlation]
&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/1_2.png&quot; alt=&quot;1_2&quot; /&gt;
[Convolution]
&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/1_1.png&quot; alt=&quot;1_1&quot; /&gt;
K(âˆ’m,âˆ’n) == K(m,n)ì¼ ë•Œ, Convolution ê³¼ Cross-Correlationì´ ë™ì¼í•˜ë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/3.gif&quot; alt=&quot;3&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ğ‘¥ğ‘–ğ‘— ëŠ” ê°ê° ì…ë ¥ê°’ì˜ ğ‘–ë²ˆì§¸ í–‰, ğ‘—ë²ˆì§¸ ì—´ì˜ ìš”ì†Œ&lt;/li&gt;
  &lt;li&gt;3x3 í–‰ë ¬, 2x2 í•„í„°(ì»¤ë„), ìŠ¤íŠ¸ë¼ì´ë“œ 1&lt;/li&gt;
  &lt;li&gt;ì´í›„ conv ë ˆì´ì–´ì— ìµœëŒ€ê°’ì´ë‚˜ í‰ê· ê°’ì„ ì·¨í•´ì„œ ì •ë³´ë¥¼ ì••ì¶•(pooling)ë˜ì–´ 2x2 í–‰ë ¬ì´ 2x1 ë²¡í„°ë¡œ ë°”ë€ë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;cnn-backward-pass&quot;&gt;CNN backward pass&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;[Average Pooling ë ˆì´ì–´ì˜ ê·¸ë˜ë””ì–¸íŠ¸ ì „íŒŒ ê³¼ì •]&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;CNN ì—­ì „íŒŒ ê³µì‹ (ê°€ì¤‘ì¹˜ ë³€í™”ì— ë”°ë¥¸ ì˜¤ì°¨ ë³€í™”ëŸ‰)&lt;/li&gt;
  &lt;li&gt;HxW feature Map, k1 x k2 kernel ì¼ ë•Œ, outputì€ (H-k1+1),(W-k2+1)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/eq_1.png&quot; alt=&quot;eq_1&quot; /&gt;
&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/eq_2.png&quot; alt=&quot;eq_2&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;í˜„ì¬ ì§€ì (x)ì˜ ê·¸ë˜ë””ì–¸íŠ¸ ì‹
&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/eq_3.png&quot; alt=&quot;eq_3&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;ìµœì¢… ì‹
&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/eq_4.png&quot; alt=&quot;eq_4&quot; width=&quot;50%&quot; height=&quot;45%&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[Average Pooling]
&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/4.png&quot; alt=&quot;4&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ë°”ë¡œ ë’¤ ë ˆì´ì–´ë¡œë¶€í„° ì „íŒŒëœ ê·¸ë˜ë””ì–¸íŠ¸ê°€ ğ‘‘1, ğ‘‘2&lt;/li&gt;
  &lt;li&gt;í˜„ì¬ ì§€ì ì˜ ê·¸ë˜ë””ì–¸íŠ¸ëŠ” ë¯¸ë¶„ì˜ ì—°ì‡„ë²•ì¹™(chain rule)ì— ì˜í•´ í˜ëŸ¬ë“¤ì–´ì˜¨ ê·¸ë˜ë””ì–¸íŠ¸(d)ì— ë¡œì»¬ ê·¸ë˜ë””ì–¸íŠ¸(w í˜¹ì€ x)ë¥¼ ê³±í•œ ê²ƒê³¼ ê°™ìŒ&lt;/li&gt;
  &lt;li&gt;Average Poolingì„ í•˜ëŠ” ì§€ì ì˜ ë¡œì»¬ ê·¸ë˜ë””ì–¸íŠ¸ëŠ” 1/ğ‘š&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[Max Pooling]
&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/5.png&quot; alt=&quot;5&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ê°€ì¥ í° ê°’ì´ ì†í•´ ìˆëŠ” ìš”ì†Œì˜ ë¡œì»¬ ê·¸ë˜ë””ì–¸íŠ¸ëŠ” 1, ë‚˜ë¨¸ì§€ëŠ” 0&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[Convolution Layer]
&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/6.png&quot; alt=&quot;6&quot; width=&quot;85%&quot; height=&quot;85%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ğ‘¥11 ì€ forward pass ê³¼ì •ì—ì„œ 2x2í•„í„° ê°€ìš´ë° ë¹¨ê°„ìƒ‰(ğ‘¤1) 
ê°€ì¤‘ì¹˜í•˜ê³ ë§Œ í•©ì„±ê³±ì´ ìˆ˜í–‰ ë˜ë¯€ë¡œ ì—­ì „íŒŒ ë•Œë„ ë§ˆì°¬ê°€ì§€ë¡œ ë”± í•œë²ˆì˜ ì—­ì „íŒŒê°€ ì¼ì–´ë‚¨&lt;/li&gt;
  &lt;li&gt;Kapathyì˜ ê³„ì‚°ê·¸ë˜í”„ í˜•íƒœë¡œ ë‚˜íƒ€ë‚´ë©´ &lt;strong&gt;ğ‘¥11 ì˜ ê·¸ë˜ë””ì–¸íŠ¸&lt;/strong&gt;ëŠ” í˜ëŸ¬ë“¤ì–´ì˜¨ ê·¸ë˜ë””ì–¸íŠ¸
ğ‘‘11ì— ë¡œì»¬ ê·¸ë˜ë””ì–¸íŠ¸(ğ‘¤1)ë¥¼ ê³±í•´ì„œ êµ¬í•  ìˆ˜ ìˆë‹¤.&lt;/li&gt;
  &lt;li&gt;ë§ˆì°¬ê°€ì§€ë¡œ &lt;strong&gt;ğ‘¤1 ì˜ ê·¸ë˜ë””ì–¸íŠ¸&lt;/strong&gt;ëŠ” í˜ëŸ¬ë“¤ì–´ì˜¨ ê·¸ë˜ë””ì–¸íŠ¸ ğ‘‘11ì— ë¡œì»¬ ê·¸ë˜ë””ì–¸íŠ¸(ğ‘¥11)ë¥¼ ê³±í•´ ê³„ì‚°&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/7.png&quot; alt=&quot;7&quot; width=&quot;85%&quot; height=&quot;85%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;í•˜ì§€ë§Œ ì´ë ‡ê²Œ í•˜ë‚˜í•˜ë‚˜ ë”°ì ¸ê°€ë©´ì„œ êµ¬í•˜ë ¤ë©´ ì‹ì´ ë³µì¡í•˜ê³  ì´í•´ê°€ ì–´ë µë‹¤.&lt;/li&gt;
  &lt;li&gt;conv layerê°€ ì—­ì „íŒŒë¥¼ í•  ë•Œ ì•½ê°„ì˜ íŠ¸ë¦­ì„ ì“°ë©´ ì¡°ê¸ˆ ë” ê°„ë‹¨íˆ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;ê°„ë‹¨í•œ ë°©ë²•&lt;/strong&gt;
&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/5_1.png&quot; alt=&quot;5_1&quot; width=&quot;85%&quot; height=&quot;85%&quot; /&gt;
&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/8.png&quot; alt=&quot;8&quot; width=&quot;85%&quot; height=&quot;85%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;í˜ëŸ¬ë“¤ì–´ì˜¨ ê·¸ë˜ë””ì–¸íŠ¸ í–‰ë ¬ì—(2x2 í¬ê¸°)ì„ conv layerë¥¼ ë§Œë“¤ ë•Œ ì¼ë˜ í•„í„°ê°€ ìŠ¬ë¼ì´ë”©í•˜ë©´ì„œ ê°’ì„ êµ¬í•œë‹¤&lt;/li&gt;
  &lt;li&gt;í•„í„° ìš”ì†Œì˜ ìˆœì„œë¥¼ ì •ë°˜ëŒ€ë¡œ ë°”ê¿” ì˜ˆì»¨ëŒ€ ë¹¨-íŒŒ-ë…¸-ì´ˆ í•„í„°ë¥¼ ì´ˆ-ë…¸-íŒŒ-ë¹¨ í•„í„°ë¡œ ë°”ê¿”ì„œ 
ê·¸ë˜ë””ì–¸íŠ¸ í–‰ë ¬ì— í•©ì„±ê³±ì„ ìˆ˜í–‰í•´ì£¼ë©´ ì…ë ¥ë²¡í„°(x)ì— ëŒ€í•œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤.&lt;/li&gt;
  &lt;li&gt;í•„í„°ì˜ ê·¸ë˜ë””ì–¸íŠ¸ëŠ” ê·¸ë˜ë””ì–¸íŠ¸ í–‰ë ¬ ì²«ë²ˆì§¸ ìš”ì†Œì¸ ğ‘‘11ì€ ğ‘¥11, ğ‘¥12, ğ‘¥21, ğ‘¥22ì™€ ì—°ê²°ë˜ì–´ ìˆëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìˆë‹¤. (ì˜í–¥ì„ ë¼ì¹˜ëŠ” ê³³)
í˜ëŸ¬ë“¤ì–´ì˜¨ ê·¸ë˜ë””ì–¸íŠ¸(ğ‘‘11, ğ‘‘12, ğ‘‘21, ğ‘‘22)ì— ë¡œì»¬ ê·¸ë˜ë””ì–¸íŠ¸(x11, x12, x21, x22)ë¥¼ ê³±í•œë‹¤.&lt;/li&gt;
  &lt;li&gt;ê°ê°ì˜ ë¡œì»¬ ê·¸ë˜ë‹¤ì–¸íŠ¸ëŠ” í•©ì„±ê³± í•„í„° ê°€ì¤‘ì¹˜ë¡œ ì—°ê²°ëœ ì…ë ¥ê°’ë“¤ì´ê¸° ë•Œë¬¸ì— ğ‘‘ğ‘¤11ì€ ğ‘¥11ğ‘‘11+ğ‘¥12ğ‘‘12+ğ‘¥21ğ‘‘21+ğ‘¥22ğ‘‘22&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;p&gt;ì°¸ì¡° ë¬¸í—Œ&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://cs231n.github.io/optimization-2/&quot;&gt;https://cs231n.github.io/optimization-2/&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/&quot;&gt;https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://ratsgo.github.io/deep%20learning/2017/04/05/CNNbackprop/&quot;&gt;https://ratsgo.github.io/deep%20learning/2017/04/05/CNNbackprop/&lt;/a&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>John</name>
        
        
      </author>

      

      
        <category term="data" />
      

      
        <summary type="html">CNN ê°•ì¢ŒëŠ” ì—¬ëŸ¬ ì ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ(CNN, Convolution Neural Network) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 2(ì—­ì „íŒŒ, Backpropagation) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 3(ë°°ì¹˜ì •ê·œí™”, Batch Normalization) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 4(ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”, Weight Initialization) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 5(VGGNet, Very Deep Convolutional Network) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 6(ResNet, Residual Learning for Image Recognition)</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ(CNN, Convolution Neural Network)</title>
      <link href="http://localhost:4000/cnn-basic" rel="alternate" type="text/html" title="í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ(CNN, Convolution Neural Network)" />
      <published>2022-01-16T21:00:00+09:00</published>
      <updated>2022-01-16T21:00:00+09:00</updated>
      <id>http://localhost:4000/cnn-basic</id>
      <content type="html" xml:base="http://localhost:4000/cnn-basic">&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;CNN ê°•ì¢ŒëŠ” ì—¬ëŸ¬ ì ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ(CNN, Convolution Neural Network)&lt;/a&gt;&lt;/li&gt; &lt;!-- í™•ì¥ì X ì‹œê°„ X íŒŒì¼ì˜ ì´ë¦„ë§Œ ì‘ì„±--&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-2&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 2(ì—­ì „íŒŒ, Backpropagation)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-3&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 3(ë°°ì¹˜ì •ê·œí™”, Batch Normalization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-4&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 4(ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”, Weight Initialization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-5&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 5(VGGNet, Very Deep Convolutional Network)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-6&quot;&gt;í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 6(ResNet, Residual Learning for Image Recognition)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;cnnì´ë€&quot;&gt;CNNì´ë€?&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Convolutionì„ ì´ìš©í•œ ì´ë¯¸ì§€ ì²˜ë¦¬ì— íƒì›”í•œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ì¸ê³µì‹ ê²½ë§&lt;/li&gt;
  &lt;li&gt;ì´ë¯¸ì§€ ê²½ìš° ì´ë™ë˜ì—ˆê±°ë‚˜, ë°©í–¥ì´ ë’¤í‹€ë ¸ê±°ë‚˜ ë“± ë‹¤ì–‘í•œ ë³€í˜•ì´ ì¡´ì¬í•œë‹¤. ê¸°ì¡´ MLPëŠ” í”½ì…€ ê°’ì´ ì•½ê°„ ë‹¬ë¼ì ¸ë„ ë¯¼ê°í•˜ê²Œ ì˜í–¥ì„ ë°›ëŠ”ë‹¤ëŠ” ë‹¨ì &lt;/li&gt;
  &lt;li&gt;ë°ì´í„°ì˜ ê³µê°„ì  ì •ë³´ë¥¼ ìœ ì§€í•˜ë©´ì„œ ë°°ì—´ ë°ì´í„° ì •ë³´ë¥¼ ë‹¤ìŒ ë ˆì´ì–´ë¡œ ë³´ë‚¼ ìˆ˜ ìˆì–´ì„œ ì´ë¯¸ì§€(RGB ì±„ë„ì˜ 3ì°¨ì› ë°°ì—´) ë¶„ì•¼ì—ì„œ ì ê·¹ í™œìš©&lt;/li&gt;
  &lt;li&gt;ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì„ ëšœë ·í•˜ê²Œ ê²€ì¶œí•˜ê¸° ë•Œë¬¸ì— ì´ë¯¸ì§€ ë¶„ë¥˜ì—ì„œ ë†’ì€ ì„±ëŠ¥&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-16/22-01-16-cnn_basic.png&quot; alt=&quot;cnn_basic&quot; /&gt;&lt;/p&gt;

&lt;p&gt;CNNì—ì„œëŠ” í•„í„°ë¥¼ ì´ìš©í•œ Convolutionì—°ì‚°ì„ ë°˜ë³µì ìœ¼ë¡œ ì§„í–‰í•˜ë©´ì„œ ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì„ ê²€ì¶œí•˜ê¸° ë•Œë¬¸ì— ìƒê°ë³´ë‹¤ êµ¬ì¡°ê°€ ê°„ë‹¨í•©ë‹ˆë‹¤. 
&lt;strong&gt;ë‹¤ìŒì˜ ì„¸ ê°€ì§€ layer&lt;/strong&gt;ë¥¼ ê¸°ì–µí•˜ì‹œë©´ ë©ë‹ˆë‹¤.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Convolution layer : íŠ¹ì§• ì¶”ì¶œ(feature extraction)&lt;/li&gt;
  &lt;li&gt;Pooling layer : íŠ¹ì§• ì¶”ì¶œ(feature extraction)&lt;/li&gt;
  &lt;li&gt;Fully-connected layer : ë¶„ë¥˜(classificaiton)&lt;br /&gt;
&lt;img src=&quot;../../assets/built/images/cnn/22-01-16/22-01-16-cnn_basic_2.png&quot; alt=&quot;cnn_basic_2&quot; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;[ í•™ìŠµ ë‚´ìš© ]&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;í•„í„° (ì»¤ë„)&lt;/li&gt;
  &lt;li&gt;íŒ¨ë”©, ìŠ¤íŠ¸ë¼ì´ë“œ&lt;/li&gt;
  &lt;li&gt;Pooling&lt;/li&gt;
  &lt;li&gt;ReLu í™œì„±í™” í•¨ìˆ˜&lt;/li&gt;
  &lt;li&gt;Fully-Connected layer&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;í•„í„°ì»¤ë„&quot;&gt;í•„í„°(ì»¤ë„)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-16/22-01-16-filter.gif&quot; alt=&quot;filter&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ì»¤ë„(kernel)ì´ë¼ê³ ë„ ë¶ˆë¦¬ë©° ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì„ ì°¾ì•„ë‚´ê¸° ìœ„í•œ ê³µìš© íŒŒë¼ë¯¸í„°&lt;/li&gt;
  &lt;li&gt;í•„í„° í†µê³¼ ì´ë¯¸ì§€ëŠ” íŠ¹ì„±ê°’ì„ ê°€ì§€ê³  ìˆì–´ feature map ë˜ëŠ” activation map ë¼ê³ í•¨&lt;/li&gt;
  &lt;li&gt;ì´ë¯¸ì§€ í”½ì…€ ê°’ì€ Convolution ì—°ì‚°ì— ì˜í•´ ë³€í™˜ë˜ê³  ì´ ê³¼ì •ì—ì„œ ìƒ‰ìƒ, ì„ , í˜•íƒœ, ê²½ê³„ ë“±ì˜ íŠ¹ì§•(feature)ì´ ëšœë ·í•´ì§&lt;/li&gt;
  &lt;li&gt;í•„í„°ê°€ ë§ì„ìˆ˜ë¡ ë” ë§ì€ ì´ë¯¸ì§€ íŠ¹ì„±ì„ ì¶”ì¶œí•˜ë©°, ì»¨ë³¼ë£¨ì…˜ ì—°ì‚°ì´ ì§„í–‰í•˜ë©´ í• ìˆ˜ë¡ ì´ë¯¸ì§€ í¬ê¸°ëŠ” ì‘ì•„ì§€ê³  ì±„ë„ ìˆ˜ëŠ” ì¦ê°€&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;íŒ¨ë”©-ìŠ¤íŠ¸ë¼ì´ë“œ&quot;&gt;íŒ¨ë”©, ìŠ¤íŠ¸ë¼ì´ë“œ&lt;/h3&gt;

&lt;p&gt;ì»¨ë³¼ë£¨ì…˜ ì—°ì‚°ì„ ê³„ì†í•  ê²½ìš°, ì´ë¯¸ì§€ í¬ê¸°ê°€ ì‘ì•„ì ¸ ì–´ë–»ê²Œ ë ê¹Œìš”?
ì—°ì‚°í•  ìˆ˜ ìˆëŠ” í”½ì…€ì´ ì—†ì–´ ë” ì´ìƒ í›ˆë ¨í•  ìˆ˜ ì—†ê²Œ ë©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-16/22-01-16-padding.svg&quot; alt=&quot;padding&quot; /&gt;&lt;br /&gt;
&lt;strong&gt;íŒ¨ë”© (Padding)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Networkê°€ ê¹Šì–´ì§€ë©´ ì´ë¯¸ì§€ í¬ê¸°ê°€ ë¬´í•œì • ì‘ì•„ì§€ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•´ íŒ¨ë”©ì´ ì¡´ì¬&lt;/li&gt;
  &lt;li&gt;ì´ë¯¸ì§€ í…Œë‘ë¦¬ì— ì¼ì • ê°’(0 ë˜ëŠ” 1)ì„ ë„£ì–´ì£¼ëŠ” ì‘ì—…&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;â–¶ íŒ¨ë”© íš¨ê³¼&lt;br /&gt;
â‘  í•©ì„±ê³± ì—°ì‚°ì„ í•  ë•Œë§ˆë‹¤ ì´ë¯¸ì§€ ì¶•ì†Œ ë¬¸ì œ ë°œìƒ â†’ ì—°ì‚° ê²°ê³¼ ì‹¤ì œ ì…ë ¥ëœ ì´ë¯¸ì§€ì™€ ê°™ì€ í¬ê¸° ì¶œë ¥&lt;br /&gt;
â‘¡ í…Œë‘ë¦¬ì— ìœ„ì¹˜í•œ í”½ì…€ì€ í•„í„° ê²°ê³¼ ë‹¨ í•œë²ˆë§Œ ì‚¬ìš© â†’ íŒ¨ë”©ìœ¼ë¡œ ì—°ì‚° ë‘ë²ˆ ì§„í–‰(í…Œë‘ë¦¬ ì´ë¯¸ì§€ ì •ë³´ ê°€ì ¸ì˜´)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ìŠ¤íŠ¸ë¼ì´ë“œ (Stride)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-16/22-01-16-stride.png&quot; alt=&quot;stride&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ì´ë¯¸ì§€ì— í•„í„°ë¥¼ ì ìš©í•˜ëŠ” ê°„ê²©&lt;/li&gt;
  &lt;li&gt;ìŠ¤íŠ¸ë¼ì´ë“œ ê°’ì„ í¬ê²Œ ì£¼ë©´ ì´ë™ ê°„ê²©ì´ ë„“ì–´ì ¸ ì¶œë ¥ ë°ì´í„°ì˜ í¬ê¸°ê°€ ì‘ì•„ì§&lt;/li&gt;
  &lt;li&gt;íŒ¨ë”©ê³¼ ë‹¤ë¥´ê²Œ ìŠ¤íŠ¸ë¼ì´ë“œëŠ” ì¶œë ¥ë°ì´í„°ì˜ í¬ê¸°ë¥¼ ì¶•ì†Œì‹œí‚¤ëŠ” ì—­í• &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;í’€ë§&quot;&gt;í’€ë§&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-16/22-01-16-pooling.png&quot; alt=&quot;pooling&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Pooling layerëŠ” ëŒ€ë¶€ë¶„ convolutional layer ë°”ë¡œ ë‹¤ìŒì— ìœ„ì¹˜í•´ ê³µê°„(spatial size)ì„ ì¶•ì†Œ&lt;/li&gt;
  &lt;li&gt;ì±„ë„ í¬ê¸°ëŠ” ê³ ì •ë˜ë©° ì…ë ¥ ë°ì´í„°ì˜ í¬ê¸°ê°€ ì¶•ì†Œë˜ê³  í•™ìŠµí•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ì¤„ì–´ë“¤ì–´ ì˜¤ë²„í”¼íŒ…(Overfitting) ë°©ì§€&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ì˜¤ë²„í”¼íŒ…(Overfitting) : ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ì—ë§Œ ì˜ ë§ì¶°ì§„ ê²½ìš°ë¡œ ê²°ê³¼ê°€ í›ˆë ¨ ë°ì´í„° ì •í™•ë„ëŠ” ë†’ì§€ë§Œ ìƒˆë¡­ê²Œ ì…ë ¥ ë°›ëŠ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì •í™•ë„ëŠ” ë‚®ì•„ ëª¨ë¸ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ëŠ” í˜„ìƒ&lt;br /&gt;
í’€ë§(Pooling)ì—ëŠ” ë§¥ìŠ¤ í’€ë§(Max Pooing)ê³¼ í‰ê·  í’€ë§(Average Pooling)ì´ ì¡´ì¬&lt;/p&gt;

&lt;p&gt;â‘  ë§¥ìŠ¤ í’€ë§(Max Pooing) : ëŒ€ìƒ ì´ë¯¸ì§€ ì˜ì—­ì—ì„œ ìµœëŒ€ê°’ì„ êµ¬í•¨ 
â‘¡ í‰ê·  í’€ë§(Average Pooling) : ëŒ€ìƒ ì´ë¯¸ì§€ ì˜ì—­ì—ì„œ í‰ê· ê°’ì„ êµ¬í•¨&lt;br /&gt;
â€» stride =2 ë¥¼ íŠ¹ì§•ìœ¼ë¡œ í•¨&lt;/p&gt;

&lt;p&gt;[CNN ë°°ì—´ ê³µì‹]&lt;br /&gt;
&lt;img src=&quot;../../assets/built/images/cnn/22-01-16/22-01-16-cal.png&quot; alt=&quot;cal&quot; width=&quot;600&quot; height=&quot;250&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;relu&quot;&gt;ReLu&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-16/22-01-16-relu.png&quot; alt=&quot;relu&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ReLu(Rectified Linear Unit) í™œì„±í™” í•¨ìˆ˜ëŠ” ë¹„ì„ í˜•ì„± í•¨ìˆ˜ë¡œ ê¸°ë³¸ ì„ í˜• íŠ¹ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” layerì— ë¹„ì„ í˜•ì„±ì„ ì¦ê°€&lt;/li&gt;
  &lt;li&gt;ReLu í•¨ìˆ˜ì˜ ë²”ìœ„ëŠ” R(z)=max(0, z) ì–‘ìˆ˜ì´ê¸° ë•Œë¬¸ì— vanishing gradient ë¬¸ì œì ì„ ê·¹ë³µí•˜ê³  í•™ìŠµ ì†ë„ì™€ ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼œ CNNì—ì„œ ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” í™œì„±í™” í•¨ìˆ˜&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;fully-connected-layer&quot;&gt;Fully-Connected layer&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-16/22-01-16-fully.png&quot; alt=&quot;fully&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;CNN ë§ˆì§€ë§‰ì—ì„œ ë¶„ë¥˜(Classification)ë¥¼ ê²°ì •í•˜ëŠ” ë‹¨ê³„&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;flatten : ê° ë ˆì´ì–´ë¥¼ 1ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜&lt;/li&gt;
  &lt;li&gt;fully-conneced layer : 1ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜ëœ ë ˆì´ì–´ë¥¼ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ì—°ê²° (ê° ì¸µì˜ ë…¸ë“œë“¤ì€ í•˜ë‚˜ë¡œ ì—°ê²°)&lt;br /&gt;
ë§ˆì§€ë§‰ìœ¼ë¡œ Softmax í•¨ìˆ˜ë¥¼ ì´ìš©í•´ ê°€ì¥ í™•ë¥ ì´ ë†’ì€ classë¥¼ outputìœ¼ë¡œ ë¶„ë¥˜&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
&lt;p&gt;ì°¸ì¡° ë¬¸í—Œ&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks#layer&quot;&gt;https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks#layer&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://seongkyun.github.io/study/2019/01/25/num_of_parameters/&quot;&gt;https://seongkyun.github.io/study/2019/01/25/num_of_parameters/&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;http://taewan.kim/post/cnn/&quot;&gt;http://taewan.kim/post/cnn/&lt;/a&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>John</name>
        
        
      </author>

      

      
        <category term="data" />
      

      
        <summary type="html">CNN ê°•ì¢ŒëŠ” ì—¬ëŸ¬ ì ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ(CNN, Convolution Neural Network) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 2(ì—­ì „íŒŒ, Backpropagation) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 3(ë°°ì¹˜ì •ê·œí™”, Batch Normalization) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 4(ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”, Weight Initialization) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 5(VGGNet, Very Deep Convolutional Network) í•©ì„±ê³± ì‹ ê²½ë§ ê¸°ì´ˆ 6(ResNet, Residual Learning for Image Recognition)</summary>
      

      
      
    </entry>
  
</feed>
