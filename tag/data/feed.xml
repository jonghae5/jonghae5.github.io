<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator>
  <link href="http://localhost:4000/tag/data/feed.xml" rel="self" type="application/atom+xml" />
  <link href="http://localhost:4000/" rel="alternate" type="text/html" />
  <updated>2022-02-16T22:55:49+09:00</updated>
  <id>http://localhost:4000/tag/data/feed.xml</id>

  
  
  

  
    <title type="html">John’s IT Blog | </title>
  

  
    <subtitle>AI &amp; Frontend Developer</subtitle>
  

  

  
    
      
    
  

  
  

  
    <entry>
      <title type="html">합성곱 신경망 기초 6(ResNet, Residual Learning for Image Recognition)</title>
      <link href="http://localhost:4000/cnn-basic-6" rel="alternate" type="text/html" title="합성곱 신경망 기초 6(ResNet, Residual Learning for Image Recognition)" />
      <published>2022-01-27T21:00:00+09:00</published>
      <updated>2022-01-27T21:00:00+09:00</updated>
      <id>http://localhost:4000/cnn-basic-6</id>
      <content type="html" xml:base="http://localhost:4000/cnn-basic-6">&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;CNN 강좌는 여러 절로 구성되어 있습니다. &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic&quot;&gt;합성곱 신경망 기초(CNN, Convolution Neural Network)&lt;/a&gt;&lt;/li&gt; &lt;!-- 확장자 X 시간 X 파일의 이름만 작성--&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-2&quot;&gt;합성곱 신경망 기초 2(역전파, Backpropagation)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-3&quot;&gt;합성곱 신경망 기초 3(배치정규화, Batch Normalization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-4&quot;&gt;합성곱 신경망 기초 4(가중치 초기화, Weight Initialization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-5&quot;&gt;합성곱 신경망 기초 5(VGGNet, Very Deep Convolutional Network)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-6&quot;&gt;합성곱 신경망 기초 6(ResNet, Residual Learning for Image Recognition)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;resnet&quot;&gt;ResNet&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;ILSVRC 2015 우승 (3.6% Top 5 Error)한 모델이며 Deep Residual Learning 이라고도 부른다.&lt;/li&gt;
  &lt;li&gt;152개의 Layer 구조이며 8배 깊은 Layers를 가졌음에도 불구하고 실행 시간이 VGGNet보다 빠르다.&lt;/li&gt;
  &lt;li&gt;이 모델은 일반적인 레이어만 깊은 모델들과 비교했을 때 성능이 좋을 뿐만 아니라 학습 속도도 더 빠르다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;introduction&quot;&gt;Introduction&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;VGGNet 논문에서 CNN 의 레이어가 깊어질수록 성능이 더 좋다는 것을 확인할 수 있었다.&lt;/li&gt;
  &lt;li&gt;하지만 레이어가 너무 깊어지면 Vanishing/Exploding gradient, 그리고 degradation problem 크게 이 두 가지 문제점에 봉착한다.&lt;/li&gt;
  &lt;li&gt;우선 Vanishing/Exploding gradient 같은 경우에는 레이어 사이에 batchNorm 을 적용해주면 해결할 수 있다.
&lt;img src=&quot;../../assets/built/images/cnn/22-01-27/2.png&quot; alt=&quot;2&quot; width=&quot;65%&quot; height=&quot;65%&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Degradation Problem 이란 정확도가 어느 순간부터 정체되고 레이어가 더 깊어질수록 성능이 더 나빠지는 현상을 의미한다.&lt;/p&gt;

&lt;p&gt;이 논문에서는 Residual Learning 을 통해 Degradation Problem 을 해결하는 방법을 제시한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-27/3.png&quot; alt=&quot;3&quot; width=&quot;65%&quot; height=&quot;65%&quot; /&gt;
&lt;img src=&quot;../../assets/built/images/cnn/22-01-27/0.png&quot; alt=&quot;0&quot; width=&quot;30%&quot; height=&quot;30%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;간단하게 input 을 x, input이 통과하는 Function 을 F(x), 그리고 Output 을 H(x) 이라고 가정해보자. F(x) = H(x) - x 를 최소화시키는 Residual mapping으로 H(x)를 재정의한다. &lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;Residual Learning 에서는 F(x) 를 H(x) - x 라고 define 해 주었다. 원래 Output H(x) 에서 자기 자신인 x 를 빼주기 때문에 ‘Residual Learning’ 이라는 이름을 가지게 된다. &lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;또 x 가 이 F(x) 를 통과한 이후에, 이 값은 자기 자신인 x 와 더해주고, Layer를 Skip해서 더해주기에 ‘Skip Connections’ 이라고 부른다. 이 Residual Block 을 통과하고 나면 최종적인 값은 F(x) + x 가 나오게 된다.&lt;/li&gt;
  &lt;li&gt;F(x) 와 x 를 직접적으로 더해주기 위해선 F(x) 와 x 가 서로 같은 Dimension 이어야 한다. 일반적으로 F(x) 와 이전의 input x가 채널수가 같다면 별다른 조치를 취해주지 않아도 그냥 더해주면 된다.&lt;/li&gt;
  &lt;li&gt;하지만 Channel 개수가 달라지거나 MaxPool 등에 의해서 x 의 크기가 달라질 때, padding 이나 별다른 Ws 를 곱해주어서 사이즈를 매칭 시켜주는 것이 중요하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;resnet-architecture&quot;&gt;ResNet Architecture&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-27/4.png&quot; alt=&quot;4&quot; width=&quot;65%&quot; height=&quot;65%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ResNet 의 기본 구조는 VGGNet-34 을 따른다. 위 그림을 보면 VGG-34 과 모델 구성은 같은데, 레이어 두개마다 Skip Connection 을 해준다는 것을 볼 수 있다.&lt;/li&gt;
  &lt;li&gt;중간에 점선으로 표시된 Skip Connection 은 x 와 F(x) 의 Dimension 이 달라져서 따로 맞춰줘야 되는 Skip Connection 들을 의미한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;deeper-bottleneck-architectures&quot;&gt;Deeper Bottleneck Architectures&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-27/7.png&quot; alt=&quot;7&quot; width=&quot;65%&quot; height=&quot;65%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;네트워크의 깊이가 50 을 넘어가면, 제아무리 ResNet을 이용하고 3x3 필터만 사용한다 할지라도 Training 시간이 매우 길어질 수 있다. 따라서 이 경우엔 원래 모델 구조에서 약간의 수정이 필요하다.&lt;/li&gt;
  &lt;li&gt;3x3 필터를 두 번 사용하는 대신, 1x1 -&amp;gt; 3x3 -&amp;gt; 1x1 필터들을 사용하는 구조를 만든다. 이렇게 수정한 구조는 Dimension 의 크기를 줄일 뿐만 아니라 시간 복잡도도 줄이는 효과를 볼 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;experiments&quot;&gt;Experiments&lt;/h3&gt;
&lt;p&gt;ResNet 은 1000개의 클라스로 이루어진 ImageNet 2012 데이터셋으로 training
&lt;img src=&quot;../../assets/built/images/cnn/22-01-27/5.png&quot; alt=&quot;5&quot; width=&quot;65%&quot; height=&quot;65%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;위 그래프에서 왼쪽 그림은 Plain Network 의 18, 34 Layer, 오른쪽 그림은 ResNet 의 18, 34 layer 의 Loss 과정이다.&lt;/li&gt;
  &lt;li&gt;우선 왼쪽 그림에서는 Degradation Problem 이 보이는 것을 확인할 수 있다. 34-Layer 네트워크가 18-layer 보다 Loss 가 높기 때문이다.&lt;/li&gt;
  &lt;li&gt;반면 ResNet 같은 경우엔 34-Layer 가 Loss 가 더 낮게 나오는 것을 확인할 수 있다. Degradation Problem 이 해결됐음을 보여주는 그래프이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-27/6.png&quot; alt=&quot;6&quot; width=&quot;65%&quot; height=&quot;65%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;위 표에서는 더 깊은 ResNet 들의 성능을 보여준다. 레이어가 깊어지면 깊어질수록 error 는 줄어드는 경향성을 볼 수 있고, 110 개의 레이어가 있을 때 가장 적은 에러가 나온다.&lt;/li&gt;
  &lt;li&gt;하지만 그렇다고 너무 깊어지면, 예를 들어 1000 개 이상의 레이어가 존재할 때는 오버피팅으로 인하여 성능이 더 얕은 모델들보다 더 안 좋게 나온다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;p&gt;참조 문헌&lt;br /&gt;
[1] He, K., Zhang, X., Ren, S., &amp;amp; Sun, J. (2016). Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 770-778).&lt;br /&gt;
&lt;a href=&quot;https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf&quot;&gt;https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf&lt;/a&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>John</name>
        
        
      </author>

      

      
        <category term="data" />
      

      
        <summary type="html">CNN 강좌는 여러 절로 구성되어 있습니다. 합성곱 신경망 기초(CNN, Convolution Neural Network) 합성곱 신경망 기초 2(역전파, Backpropagation) 합성곱 신경망 기초 3(배치정규화, Batch Normalization) 합성곱 신경망 기초 4(가중치 초기화, Weight Initialization) 합성곱 신경망 기초 5(VGGNet, Very Deep Convolutional Network) 합성곱 신경망 기초 6(ResNet, Residual Learning for Image Recognition)</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">합성곱 신경망 기초 5(VGGNet, Very Deep Convolutional Network)</title>
      <link href="http://localhost:4000/cnn-basic-5" rel="alternate" type="text/html" title="합성곱 신경망 기초 5(VGGNet, Very Deep Convolutional Network)" />
      <published>2022-01-23T21:00:00+09:00</published>
      <updated>2022-01-23T21:00:00+09:00</updated>
      <id>http://localhost:4000/cnn-basic-5</id>
      <content type="html" xml:base="http://localhost:4000/cnn-basic-5">&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;CNN 강좌는 여러 절로 구성되어 있습니다. &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic&quot;&gt;합성곱 신경망 기초(CNN, Convolution Neural Network)&lt;/a&gt;&lt;/li&gt; &lt;!-- 확장자 X 시간 X 파일의 이름만 작성--&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-2&quot;&gt;합성곱 신경망 기초 2(역전파, Backpropagation)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-3&quot;&gt;합성곱 신경망 기초 3(배치정규화, Batch Normalization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-4&quot;&gt;합성곱 신경망 기초 4(가중치 초기화, Weight Initialization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-5&quot;&gt;합성곱 신경망 기초 5(VGGNet, Very Deep Convolutional Network)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-6&quot;&gt;합성곱 신경망 기초 6(ResNet, Residual Learning for Image Recognition)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;vggnet&quot;&gt;VGGNet&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;ILSVRC 2014 대회에서 2등을 차지한 Karen Simonyan과 Andrew Zisserman이 만든 CNN 모델&lt;/li&gt;
  &lt;li&gt;ILSVRC는 ImageNet Large Scale Visual Recognition Challenge의 약자로, 2010년에 시작된 이미지 인식(Image Recognition) 경진대회&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;vgg-16-architecture&quot;&gt;VGG-16 Architecture&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-23/vggnet_2.jpeg&quot; alt=&quot;1&quot; width=&quot;65%&quot; height=&quot;65%&quot; /&gt;
&lt;img src=&quot;../../assets/built/images/cnn/22-01-23/vggnet_1.png&quot; alt=&quot;0&quot; width=&quot;65%&quot; height=&quot;65%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;13 Convolution Layers + 3 Fully-connected Layers&lt;/li&gt;
  &lt;li&gt;3x3 convolution filters&lt;/li&gt;
  &lt;li&gt;stride: 1 &amp;amp; padding: 1&lt;/li&gt;
  &lt;li&gt;2x2 max pooling (stride : 2)&lt;/li&gt;
  &lt;li&gt;ReLU&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;configuration&quot;&gt;Configuration&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-23/vggnet_4.jpeg&quot; alt=&quot;4&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Input Size RGB 224x224, 복수의 Convolution layer, Max-Pooling층이 반복되는 구조이며 최종단에는 FC layer으로 구성되어 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3x3-필터-사용-why-use-smaller-filters&quot;&gt;3x3 필터 사용 (Why use smaller filters?)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;VGG 모델 이전 Convolutional Network를 활용하여 이미지 분류에서 좋은 성과를 보였던 모델들은 비교적 큰 Receptive Field를 갖는 11x11필터나 7x7 필터를 포함&lt;/li&gt;
  &lt;li&gt;그러나 VGG 모델은 오직 3x3 크기의 작은 필터만 사용했음에도 이미지 분류 정확도를 비약적으로 개선
&lt;img src=&quot;../../assets/built/images/cnn/22-01-23/vggnet_3.png&quot; alt=&quot;3&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;u&gt;파라미터 수를 줄이고 Layer를 다층 쌓아서 모델의 전체 Depth를 깊게 만들기 위해서이다.&lt;/u&gt;&lt;/li&gt;
  &lt;li&gt;Input Size가 7x7이며, 3x3의 Output Size를 도출해내야 한다고 가정하자, 이때 Filter Size가 3x3이라면 총 두 차례의 Convolution을 진행해야 한다.&lt;/li&gt;
  &lt;li&gt;반면 5x5의 Filter Size로는 단 한 번의 Convolution으로 동일한 사이즈의 Feature Map을 산출한다. 3x3 Filter로 세 차례 Convolution 하는 것은 7x7 Filter로 한 번 Convolution 하는 것과 대응된다.&lt;/li&gt;
  &lt;li&gt;즉, 3x3 Filter 3개는 7x7 Filter 하나와 동일한 Receptive Field (= Filter가 한 번에 볼 수 있는 입력 이미지의 Spatial Area) 를 가지면서도 더 깊은 레이어를 쌓을 수 있게 하는 것이다.&lt;/li&gt;
  &lt;li&gt;이처럼 Layer 수가 늘어나면 이미지 특성에 비선형성을 더 추가할 수 있기 때문에(Deeper, more non-linearities), Filter를 통해 추출한 Feature가 점점 유용해지는 이점을 얻게 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;필터의-크기가-작으면-파라미터-수도-적어진다smaller-filters-fewer-parameters&quot;&gt;필터의 크기가 작으면 파라미터 수도 적어진다(Smaller filters, fewer parameters)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;3x3 Filter에는 9개의 파라미터가 있다. 이때 Depth를 C라고 한다면 3 x 3 x C 개의 파라미터가 있고, 여기에 출력되는 Feature Map의 개수(=입력 Depth)를 곱하면 각 레이어 당 3x3xCxC의 파라미터를 가지게 된다. 만약 Layer가 3개라면, 총 파라미터는 3 * (32C2)개이다.&lt;/li&gt;
  &lt;li&gt;반면 7x7 Filter의 경우 7x7xCxC개의 파라미터 수가 있을 것이다. 레이어를 더 적게 쌓았음에도 파라미터 수가 많은 것을 확인할 수 있다.&lt;/li&gt;
  &lt;li&gt;여기서 파라미터(weight) 수가 적다는 것은 어떤 의미를 가질까? CNN에서 가중치는 모두 훈련이 필요한 것들이므로, &lt;u&gt;파라미터 수가 적을 수록 학습 속도가 빨라진다는 이점을 얻을 수 있다.&lt;/u&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;결론&quot;&gt;결론&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;VGGNet은 3x3의 작은 필터를 모든 Conv 레이어에 사용하였다.&lt;/li&gt;
  &lt;li&gt;작은 필터를 사용함으로써 더 많은 ReLU함수를 사용할 수 있고 더 많은 비선형성을 확보할 수 있었다.&lt;/li&gt;
  &lt;li&gt;VGGNet의 A~E까지 각각의 다른 모델이 아니라 학습의 단계부터 알 수 있듯, 업그레이드된 모델이다.&lt;/li&gt;
  &lt;li&gt;위와 같은 특징들로 AlexNet보다 2배 이상 깊은 네트워크이며 좋은 성능을 가진 모델을 만들어 낼 수 있었다.&lt;/li&gt;
  &lt;li&gt;줄였음에도 파라미터의 수가 엄청나게 많기 때문에 학습 시간이 오래 걸린다&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
&lt;p&gt;참조 문헌&lt;br /&gt;
&lt;a href=&quot;https://arxiv.org/pdf/1409.1556.pdf&quot;&gt;https://arxiv.org/pdf/1409.1556.pdf&lt;/a&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>John</name>
        
        
      </author>

      

      
        <category term="data" />
      

      
        <summary type="html">CNN 강좌는 여러 절로 구성되어 있습니다. 합성곱 신경망 기초(CNN, Convolution Neural Network) 합성곱 신경망 기초 2(역전파, Backpropagation) 합성곱 신경망 기초 3(배치정규화, Batch Normalization) 합성곱 신경망 기초 4(가중치 초기화, Weight Initialization) 합성곱 신경망 기초 5(VGGNet, Very Deep Convolutional Network) 합성곱 신경망 기초 6(ResNet, Residual Learning for Image Recognition)</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">합성곱 신경망 기초 4(가중치 초기화, Weight Initialization)</title>
      <link href="http://localhost:4000/cnn-basic-4" rel="alternate" type="text/html" title="합성곱 신경망 기초 4(가중치 초기화, Weight Initialization)" />
      <published>2022-01-17T21:00:00+09:00</published>
      <updated>2022-01-17T21:00:00+09:00</updated>
      <id>http://localhost:4000/cnn-basic-4</id>
      <content type="html" xml:base="http://localhost:4000/cnn-basic-4">&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;CNN 강좌는 여러 절로 구성되어 있습니다. &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic&quot;&gt;합성곱 신경망 기초(CNN, Convolution Neural Network)&lt;/a&gt;&lt;/li&gt; &lt;!-- 확장자 X 시간 X 파일의 이름만 작성--&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-2&quot;&gt;합성곱 신경망 기초 2(역전파, Backpropagation)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-3&quot;&gt;합성곱 신경망 기초 3(배치정규화, Batch Normalization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-4&quot;&gt;합성곱 신경망 기초 4(가중치 초기화, Weight Initialization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-5&quot;&gt;합성곱 신경망 기초 5(VGGNet, Very Deep Convolutional Network)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-6&quot;&gt;합성곱 신경망 기초 6(ResNet, Residual Learning for Image Recognition)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;가중치-초기화&quot;&gt;가중치 초기화&lt;/h3&gt;
&lt;p&gt;&lt;br /&gt;
&lt;strong&gt;가중치가 중요한 이유&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Overfitting-Underfitting 문제가 발생해 제대로 학습이 되지 않을 수 있다.&lt;/li&gt;
  &lt;li&gt;그래디언트 손실(Vanishing Gradient)와 폭주(Exploding)문제가 발생한다.&lt;/li&gt;
  &lt;li&gt;지역 최적화(Local Optimization)에 실패해 Local mnimum에 수렴하기도 한다.&lt;/li&gt;
  &lt;li&gt;즉, 같은 모델을 훈련시키더라도 가중치가 어떤 초기 값을 갖느냐에 따라서 모델 훈련 결과가 달라진다.
&lt;img src=&quot;../../assets/built/images/cnn/22-01-18/0.png&quot; alt=&quot;0&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;가중치 값이 0일 경우, 학습이 불가능하다.&lt;/li&gt;
  &lt;li&gt;가중치 값을 같은 값으로 할 경우, 1개 신경망에 학습시키는 것과 동일&lt;/li&gt;
  &lt;li&gt;평균 0 ,1보다 작은 표준편차 분포를 사용한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;1) Sigmoid, 정규분포&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-18/4.png&quot; alt=&quot;4&quot; width=&quot;70%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;표준편차가 크기 때문에 학습이 반복될 수록 0,1로 치우치는 문제가 발생&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2) 1)에서 표준편차를 줄였을 경우&lt;/strong&gt;
&lt;img src=&quot;../../assets/built/images/cnn/22-01-18/5.png&quot; alt=&quot;5&quot; width=&quot;70%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Sigmoid 그래디언트 최댓값이 0.25이므로 현상을 완화할 수는 있지만 0.5로 몰리는 현상&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;“더 나은 방법을 찾아보자”&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;LeCun Initialization&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;CNN LeNet 창시자 LeCun이 도입&lt;/li&gt;
  &lt;li&gt;정규분포, Uniform 분포를 따르는 방법 2가지가 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-18/6.png&quot; alt=&quot;6&quot; width=&quot;70%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Xavier Initialization&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;이전 노드와 다음 노드 개수에 의존하는 방법&lt;/li&gt;
  &lt;li&gt;비선형함수(ex. sigmoid, tanh)에서 효과적인 결과&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-18/7.png&quot; alt=&quot;7&quot; width=&quot;70%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;He Initialization&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Relu 활성화 함수 사용시, Xavier 설정이 비효율적인 결과를 가져온다.(평균, 표준편차 0으로 수렴)&lt;/li&gt;
  &lt;li&gt;최근 대부분 모델에서 He 초기화를 사용한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-18/8.png&quot; alt=&quot;8&quot; width=&quot;70%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;⭐️ 최근 Deep CNN 모델들은 &lt;span style=&quot;color:#2D3748; background-color:#fff5b1;&quot;&gt;Gaussian Distribution&lt;/span&gt; 초기화 방법 사용&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;참조 문헌
&lt;a href=&quot;https://kharshit.github.io/blog/2018/12/28/why-batch-normalization&quot;&gt;https://kharshit.github.io/blog/2018/12/28/why-batch-normalization&lt;/a&gt;
&lt;a href=&quot;https://reniew.github.io/13/&quot;&gt;https://reniew.github.io/13/&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://wooono.tistory.com/227&quot;&gt;https://wooono.tistory.com/227&lt;/a&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>John</name>
        
        
      </author>

      

      
        <category term="data" />
      

      
        <summary type="html">CNN 강좌는 여러 절로 구성되어 있습니다. 합성곱 신경망 기초(CNN, Convolution Neural Network) 합성곱 신경망 기초 2(역전파, Backpropagation) 합성곱 신경망 기초 3(배치정규화, Batch Normalization) 합성곱 신경망 기초 4(가중치 초기화, Weight Initialization) 합성곱 신경망 기초 5(VGGNet, Very Deep Convolutional Network) 합성곱 신경망 기초 6(ResNet, Residual Learning for Image Recognition)</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">합성곱 신경망 기초 3(배치정규화, Batch Normalization)</title>
      <link href="http://localhost:4000/cnn-basic-3" rel="alternate" type="text/html" title="합성곱 신경망 기초 3(배치정규화, Batch Normalization)" />
      <published>2022-01-17T21:00:00+09:00</published>
      <updated>2022-01-17T21:00:00+09:00</updated>
      <id>http://localhost:4000/cnn-basic-3</id>
      <content type="html" xml:base="http://localhost:4000/cnn-basic-3">&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;CNN 강좌는 여러 절로 구성되어 있습니다. &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic&quot;&gt;합성곱 신경망 기초(CNN, Convolution Neural Network)&lt;/a&gt;&lt;/li&gt; &lt;!-- 확장자 X 시간 X 파일의 이름만 작성--&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-2&quot;&gt;합성곱 신경망 기초 2(역전파, Backpropagation)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-3&quot;&gt;합성곱 신경망 기초 3(배치정규화, Batch Normalization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-4&quot;&gt;합성곱 신경망 기초 4(가중치 초기화, Weight Initialization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-5&quot;&gt;합성곱 신경망 기초 5(VGGNet, Very Deep Convolutional Network)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-6&quot;&gt;합성곱 신경망 기초 6(ResNet, Residual Learning for Image Recognition)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;배치-정규화&quot;&gt;배치 정규화&lt;/h3&gt;
&lt;p&gt;깊은 신경망일 수록 같은 Input 이라도 가중치가 조금이라도 다르다면 완전히 다른 결과를 가져올 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;“각 층이 활성화를 적당히 퍼뜨리도록 강제로 해보자”&lt;/strong&gt;
&lt;img src=&quot;../../assets/built/images/cnn/22-01-18/1.jpeg&quot; alt=&quot;1&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;배치란?&lt;/strong&gt; 신경망 학습시, 전체 데이터를 한 번에 학습시키지 않고, 조그만 단위로 분할해서 학습 시키는 것.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;배치 정규화란?&lt;/strong&gt; 배치 단위로 정규화 하는 것.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;[배치 정규화 알고리즘]&lt;/strong&gt;
&lt;img src=&quot;../../assets/built/images/cnn/22-01-18/2.png&quot; alt=&quot;2&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;엡실론은 분모가 0 이 되는 것을 막기 위한 아주 작은 숫자(1e-5~7)&lt;/li&gt;
  &lt;li&gt;정규화 이후, 배치 데이터들을 scale(감마(γ)), shift(베타(β)) 를 통해 새로운 값으로 바꾼다.&lt;/li&gt;
  &lt;li&gt;데이터를 계속 정규화 하게 되면, 활성화 함수의 비선형 성질을 잃게 되는 문제 발생&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;아래 그림과 같이 Sigmoid 함수 경우, 입력 값이 N(0, 1) 이라면, 95% 의 입력 값은 Sigmoid 함수 그래프의 중간 (x = (-1.96, 1.96) 구간)에 속하게 된다.
&lt;img src=&quot;../../assets/built/images/cnn/22-01-18/3.png&quot; alt=&quot;3&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;감마(γ), 베타(β)를 통해 활성함수로 들어가는 값의 범위를 변환하여 비선형 성질을 보존&lt;/li&gt;
  &lt;li&gt;감마(γ), 베타(β) 값은 학습 가능한 변수, 역전파를 통해서 학습&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;⭐&lt;strong&gt;배치 정규화 효과&lt;/strong&gt;⭐&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;학습이 빠르게 진행(Epoch 수를 줄이는데 효과적)&lt;/li&gt;
  &lt;li&gt;Dropout 필요성 감소&lt;/li&gt;
  &lt;li&gt;더 높은 Learning rate 사용 가능&lt;/li&gt;
  &lt;li&gt;규제 효과 (과적합 방지)&lt;/li&gt;
  &lt;li&gt;그래디언트 손실(Vanishing Gradient)와 폭주(Exploding)문제 해결&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
&lt;p&gt;참조 문헌
&lt;a href=&quot;https://kharshit.github.io/blog/2018/12/28/why-batch-normalization&quot;&gt;https://kharshit.github.io/blog/2018/12/28/why-batch-normalization&lt;/a&gt;
&lt;a href=&quot;https://reniew.github.io/13/&quot;&gt;https://reniew.github.io/13/&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://wooono.tistory.com/227&quot;&gt;https://wooono.tistory.com/227&lt;/a&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>John</name>
        
        
      </author>

      

      
        <category term="data" />
      

      
        <summary type="html">CNN 강좌는 여러 절로 구성되어 있습니다. 합성곱 신경망 기초(CNN, Convolution Neural Network) 합성곱 신경망 기초 2(역전파, Backpropagation) 합성곱 신경망 기초 3(배치정규화, Batch Normalization) 합성곱 신경망 기초 4(가중치 초기화, Weight Initialization) 합성곱 신경망 기초 5(VGGNet, Very Deep Convolutional Network) 합성곱 신경망 기초 6(ResNet, Residual Learning for Image Recognition)</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">합성곱 신경망 기초 2(CNN, 역전파 Backpropagation)</title>
      <link href="http://localhost:4000/cnn-basic-2" rel="alternate" type="text/html" title="합성곱 신경망 기초 2(CNN, 역전파 Backpropagation)" />
      <published>2022-01-17T21:00:00+09:00</published>
      <updated>2022-01-17T21:00:00+09:00</updated>
      <id>http://localhost:4000/cnn-basic-2</id>
      <content type="html" xml:base="http://localhost:4000/cnn-basic-2">&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;CNN 강좌는 여러 절로 구성되어 있습니다. &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic&quot;&gt;합성곱 신경망 기초(CNN, Convolution Neural Network)&lt;/a&gt;&lt;/li&gt; &lt;!-- 확장자 X 시간 X 파일의 이름만 작성--&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-2&quot;&gt;합성곱 신경망 기초 2(역전파, Backpropagation)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-3&quot;&gt;합성곱 신경망 기초 3(배치정규화, Batch Normalization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-4&quot;&gt;합성곱 신경망 기초 4(가중치 초기화, Weight Initialization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-5&quot;&gt;합성곱 신경망 기초 5(VGGNet, Very Deep Convolutional Network)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-6&quot;&gt;합성곱 신경망 기초 6(ResNet, Residual Learning for Image Recognition)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;cnn-foward-pass&quot;&gt;CNN foward pass&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/1.gif&quot; alt=&quot;1&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;CNN은 필터가 입력데이터를 슬라이딩하면서 지역적 특징(feature)을 추출&lt;/li&gt;
  &lt;li&gt;이 특징을 최대값(Max Pooling)이나 평균값(Average Pooling)으로 압축해 다음 레이어로 전달&lt;/li&gt;
  &lt;li&gt;이런 과정을 반복해 분류 등 원하는 결과를 만들어내는 것이 CNN의 일반적인 구조&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[Cross-Correlation]
&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/1_2.png&quot; alt=&quot;1_2&quot; /&gt;
[Convolution]
&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/1_1.png&quot; alt=&quot;1_1&quot; /&gt;
K(−m,−n) == K(m,n)일 때, Convolution 과 Cross-Correlation이 동일하다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/3.gif&quot; alt=&quot;3&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;𝑥𝑖𝑗 는 각각 입력값의 𝑖번째 행, 𝑗번째 열의 요소&lt;/li&gt;
  &lt;li&gt;3x3 행렬, 2x2 필터(커널), 스트라이드 1&lt;/li&gt;
  &lt;li&gt;이후 conv 레이어에 최대값이나 평균값을 취해서 정보를 압축(pooling)되어 2x2 행렬이 2x1 벡터로 바뀐다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;cnn-backward-pass&quot;&gt;CNN backward pass&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;[Average Pooling 레이어의 그래디언트 전파 과정]&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;CNN 역전파 공식 (가중치 변화에 따른 오차 변화량)&lt;/li&gt;
  &lt;li&gt;HxW feature Map, k1 x k2 kernel 일 때, output은 (H-k1+1),(W-k2+1)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/eq_1.png&quot; alt=&quot;eq_1&quot; /&gt;
&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/eq_2.png&quot; alt=&quot;eq_2&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;현재 지점(x)의 그래디언트 식
&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/eq_3.png&quot; alt=&quot;eq_3&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;최종 식
&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/eq_4.png&quot; alt=&quot;eq_4&quot; width=&quot;50%&quot; height=&quot;45%&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[Average Pooling]
&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/4.png&quot; alt=&quot;4&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;바로 뒤 레이어로부터 전파된 그래디언트가 𝑑1, 𝑑2&lt;/li&gt;
  &lt;li&gt;현재 지점의 그래디언트는 미분의 연쇄법칙(chain rule)에 의해 흘러들어온 그래디언트(d)에 로컬 그래디언트(w 혹은 x)를 곱한 것과 같음&lt;/li&gt;
  &lt;li&gt;Average Pooling을 하는 지점의 로컬 그래디언트는 1/𝑚&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[Max Pooling]
&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/5.png&quot; alt=&quot;5&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;가장 큰 값이 속해 있는 요소의 로컬 그래디언트는 1, 나머지는 0&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[Convolution Layer]
&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/6.png&quot; alt=&quot;6&quot; width=&quot;85%&quot; height=&quot;85%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;𝑥11 은 forward pass 과정에서 2x2필터 가운데 빨간색(𝑤1) 
가중치하고만 합성곱이 수행 되므로 역전파 때도 마찬가지로 딱 한번의 역전파가 일어남&lt;/li&gt;
  &lt;li&gt;Kapathy의 계산그래프 형태로 나타내면 &lt;strong&gt;𝑥11 의 그래디언트&lt;/strong&gt;는 흘러들어온 그래디언트
𝑑11에 로컬 그래디언트(𝑤1)를 곱해서 구할 수 있다.&lt;/li&gt;
  &lt;li&gt;마찬가지로 &lt;strong&gt;𝑤1 의 그래디언트&lt;/strong&gt;는 흘러들어온 그래디언트 𝑑11에 로컬 그래디언트(𝑥11)를 곱해 계산&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/7.png&quot; alt=&quot;7&quot; width=&quot;85%&quot; height=&quot;85%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;하지만 이렇게 하나하나 따져가면서 구하려면 식이 복잡하고 이해가 어렵다.&lt;/li&gt;
  &lt;li&gt;conv layer가 역전파를 할 때 약간의 트릭을 쓰면 조금 더 간단히 그래디언트를 구할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;간단한 방법&lt;/strong&gt;
&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/5_1.png&quot; alt=&quot;5_1&quot; width=&quot;85%&quot; height=&quot;85%&quot; /&gt;
&lt;img src=&quot;../../assets/built/images/cnn/22-01-17/8.png&quot; alt=&quot;8&quot; width=&quot;85%&quot; height=&quot;85%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;흘러들어온 그래디언트 행렬에(2x2 크기)을 conv layer를 만들 때 썼던 필터가 슬라이딩하면서 값을 구한다&lt;/li&gt;
  &lt;li&gt;필터 요소의 순서를 정반대로 바꿔 예컨대 빨-파-노-초 필터를 초-노-파-빨 필터로 바꿔서 
그래디언트 행렬에 합성곱을 수행해주면 입력벡터(x)에 대한 그래디언트를 구할 수 있다.&lt;/li&gt;
  &lt;li&gt;필터의 그래디언트는 그래디언트 행렬 첫번째 요소인 𝑑11은 𝑥11, 𝑥12, 𝑥21, 𝑥22와 연결되어 있는 걸 확인할 수 있다. (영향을 끼치는 곳)
흘러들어온 그래디언트(𝑑11, 𝑑12, 𝑑21, 𝑑22)에 로컬 그래디언트(x11, x12, x21, x22)를 곱한다.&lt;/li&gt;
  &lt;li&gt;각각의 로컬 그래다언트는 합성곱 필터 가중치로 연결된 입력값들이기 때문에 𝑑𝑤11은 𝑥11𝑑11+𝑥12𝑑12+𝑥21𝑑21+𝑥22𝑑22&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;p&gt;참조 문헌&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://cs231n.github.io/optimization-2/&quot;&gt;https://cs231n.github.io/optimization-2/&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/&quot;&gt;https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://ratsgo.github.io/deep%20learning/2017/04/05/CNNbackprop/&quot;&gt;https://ratsgo.github.io/deep%20learning/2017/04/05/CNNbackprop/&lt;/a&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>John</name>
        
        
      </author>

      

      
        <category term="data" />
      

      
        <summary type="html">CNN 강좌는 여러 절로 구성되어 있습니다. 합성곱 신경망 기초(CNN, Convolution Neural Network) 합성곱 신경망 기초 2(역전파, Backpropagation) 합성곱 신경망 기초 3(배치정규화, Batch Normalization) 합성곱 신경망 기초 4(가중치 초기화, Weight Initialization) 합성곱 신경망 기초 5(VGGNet, Very Deep Convolutional Network) 합성곱 신경망 기초 6(ResNet, Residual Learning for Image Recognition)</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">합성곱 신경망 기초(CNN, Convolution Neural Network)</title>
      <link href="http://localhost:4000/cnn-basic" rel="alternate" type="text/html" title="합성곱 신경망 기초(CNN, Convolution Neural Network)" />
      <published>2022-01-16T21:00:00+09:00</published>
      <updated>2022-01-16T21:00:00+09:00</updated>
      <id>http://localhost:4000/cnn-basic</id>
      <content type="html" xml:base="http://localhost:4000/cnn-basic">&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;CNN 강좌는 여러 절로 구성되어 있습니다. &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic&quot;&gt;합성곱 신경망 기초(CNN, Convolution Neural Network)&lt;/a&gt;&lt;/li&gt; &lt;!-- 확장자 X 시간 X 파일의 이름만 작성--&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-2&quot;&gt;합성곱 신경망 기초 2(역전파, Backpropagation)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-3&quot;&gt;합성곱 신경망 기초 3(배치정규화, Batch Normalization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-4&quot;&gt;합성곱 신경망 기초 4(가중치 초기화, Weight Initialization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-5&quot;&gt;합성곱 신경망 기초 5(VGGNet, Very Deep Convolutional Network)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-6&quot;&gt;합성곱 신경망 기초 6(ResNet, Residual Learning for Image Recognition)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;cnn이란&quot;&gt;CNN이란?&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Convolution을 이용한 이미지 처리에 탁월한 성능을 보이는 인공신경망&lt;/li&gt;
  &lt;li&gt;이미지 경우 이동되었거나, 방향이 뒤틀렸거나 등 다양한 변형이 존재한다. 기존 MLP는 픽셀 값이 약간 달라져도 민감하게 영향을 받는다는 단점&lt;/li&gt;
  &lt;li&gt;데이터의 공간적 정보를 유지하면서 배열 데이터 정보를 다음 레이어로 보낼 수 있어서 이미지(RGB 채널의 3차원 배열) 분야에서 적극 활용&lt;/li&gt;
  &lt;li&gt;이미지의 특징을 뚜렷하게 검출하기 때문에 이미지 분류에서 높은 성능&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-16/22-01-16-cnn_basic.png&quot; alt=&quot;cnn_basic&quot; /&gt;&lt;/p&gt;

&lt;p&gt;CNN에서는 필터를 이용한 Convolution연산을 반복적으로 진행하면서 이미지의 특징을 검출하기 때문에 생각보다 구조가 간단합니다. 
&lt;strong&gt;다음의 세 가지 layer&lt;/strong&gt;를 기억하시면 됩니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Convolution layer : 특징 추출(feature extraction)&lt;/li&gt;
  &lt;li&gt;Pooling layer : 특징 추출(feature extraction)&lt;/li&gt;
  &lt;li&gt;Fully-connected layer : 분류(classificaiton)&lt;br /&gt;
&lt;img src=&quot;../../assets/built/images/cnn/22-01-16/22-01-16-cnn_basic_2.png&quot; alt=&quot;cnn_basic_2&quot; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;[ 학습 내용 ]&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;필터 (커널)&lt;/li&gt;
  &lt;li&gt;패딩, 스트라이드&lt;/li&gt;
  &lt;li&gt;Pooling&lt;/li&gt;
  &lt;li&gt;ReLu 활성화 함수&lt;/li&gt;
  &lt;li&gt;Fully-Connected layer&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;필터커널&quot;&gt;필터(커널)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-16/22-01-16-filter.gif&quot; alt=&quot;filter&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;커널(kernel)이라고도 불리며 이미지의 특징을 찾아내기 위한 공용 파라미터&lt;/li&gt;
  &lt;li&gt;필터 통과 이미지는 특성값을 가지고 있어 feature map 또는 activation map 라고함&lt;/li&gt;
  &lt;li&gt;이미지 픽셀 값은 Convolution 연산에 의해 변환되고 이 과정에서 색상, 선, 형태, 경계 등의 특징(feature)이 뚜렷해짐&lt;/li&gt;
  &lt;li&gt;필터가 많을수록 더 많은 이미지 특성을 추출하며, 컨볼루션 연산이 진행하면 할수록 이미지 크기는 작아지고 채널 수는 증가&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;패딩-스트라이드&quot;&gt;패딩, 스트라이드&lt;/h3&gt;

&lt;p&gt;컨볼루션 연산을 계속할 경우, 이미지 크기가 작아져 어떻게 될까요?
연산할 수 있는 픽셀이 없어 더 이상 훈련할 수 없게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-16/22-01-16-padding.svg&quot; alt=&quot;padding&quot; /&gt;&lt;br /&gt;
&lt;strong&gt;패딩 (Padding)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Network가 깊어지면 이미지 크기가 무한정 작아지는 것을 막기 위해 패딩이 존재&lt;/li&gt;
  &lt;li&gt;이미지 테두리에 일정 값(0 또는 1)을 넣어주는 작업&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;▶ 패딩 효과&lt;br /&gt;
① 합성곱 연산을 할 때마다 이미지 축소 문제 발생 → 연산 결과 실제 입력된 이미지와 같은 크기 출력&lt;br /&gt;
② 테두리에 위치한 픽셀은 필터 결과 단 한번만 사용 → 패딩으로 연산 두번 진행(테두리 이미지 정보 가져옴)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;스트라이드 (Stride)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-16/22-01-16-stride.png&quot; alt=&quot;stride&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;이미지에 필터를 적용하는 간격&lt;/li&gt;
  &lt;li&gt;스트라이드 값을 크게 주면 이동 간격이 넓어져 출력 데이터의 크기가 작아짐&lt;/li&gt;
  &lt;li&gt;패딩과 다르게 스트라이드는 출력데이터의 크기를 축소시키는 역할&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;풀링&quot;&gt;풀링&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-16/22-01-16-pooling.png&quot; alt=&quot;pooling&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Pooling layer는 대부분 convolutional layer 바로 다음에 위치해 공간(spatial size)을 축소&lt;/li&gt;
  &lt;li&gt;채널 크기는 고정되며 입력 데이터의 크기가 축소되고 학습하지 않기 때문에 파라미터 수가 줄어들어 오버피팅(Overfitting) 방지&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;오버피팅(Overfitting) : 모델이 훈련 데이터에만 잘 맞춰진 경우로 결과가 훈련 데이터 정확도는 높지만 새롭게 입력 받는 테스트 데이터의 정확도는 낮아 모델 성능이 떨어지는 현상&lt;br /&gt;
풀링(Pooling)에는 맥스 풀링(Max Pooing)과 평균 풀링(Average Pooling)이 존재&lt;/p&gt;

&lt;p&gt;① 맥스 풀링(Max Pooing) : 대상 이미지 영역에서 최대값을 구함 
② 평균 풀링(Average Pooling) : 대상 이미지 영역에서 평균값을 구함&lt;br /&gt;
※ stride =2 를 특징으로 함&lt;/p&gt;

&lt;p&gt;[CNN 배열 공식]&lt;br /&gt;
&lt;img src=&quot;../../assets/built/images/cnn/22-01-16/22-01-16-cal.png&quot; alt=&quot;cal&quot; width=&quot;600&quot; height=&quot;250&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;relu&quot;&gt;ReLu&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-16/22-01-16-relu.png&quot; alt=&quot;relu&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ReLu(Rectified Linear Unit) 활성화 함수는 비선형성 함수로 기본 선형 특성을 나타내는 layer에 비선형성을 증가&lt;/li&gt;
  &lt;li&gt;ReLu 함수의 범위는 R(z)=max(0, z) 양수이기 때문에 vanishing gradient 문제점을 극복하고 학습 속도와 성능을 향상시켜 CNN에서 주로 사용되는 활성화 함수&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;fully-connected-layer&quot;&gt;Fully-Connected layer&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cnn/22-01-16/22-01-16-fully.png&quot; alt=&quot;fully&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;CNN 마지막에서 분류(Classification)를 결정하는 단계&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;flatten : 각 레이어를 1차원 벡터로 변환&lt;/li&gt;
  &lt;li&gt;fully-conneced layer : 1차원 벡터로 변환된 레이어를 하나의 벡터로 연결 (각 층의 노드들은 하나로 연결)&lt;br /&gt;
마지막으로 Softmax 함수를 이용해 가장 확률이 높은 class를 output으로 분류&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
&lt;p&gt;참조 문헌&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks#layer&quot;&gt;https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks#layer&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://seongkyun.github.io/study/2019/01/25/num_of_parameters/&quot;&gt;https://seongkyun.github.io/study/2019/01/25/num_of_parameters/&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;http://taewan.kim/post/cnn/&quot;&gt;http://taewan.kim/post/cnn/&lt;/a&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>John</name>
        
        
      </author>

      

      
        <category term="data" />
      

      
        <summary type="html">CNN 강좌는 여러 절로 구성되어 있습니다. 합성곱 신경망 기초(CNN, Convolution Neural Network) 합성곱 신경망 기초 2(역전파, Backpropagation) 합성곱 신경망 기초 3(배치정규화, Batch Normalization) 합성곱 신경망 기초 4(가중치 초기화, Weight Initialization) 합성곱 신경망 기초 5(VGGNet, Very Deep Convolutional Network) 합성곱 신경망 기초 6(ResNet, Residual Learning for Image Recognition)</summary>
      

      
      
    </entry>
  
</feed>
