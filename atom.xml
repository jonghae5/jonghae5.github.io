<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> - Articles</title>
    <description>AI &amp; Backend Developer</description>
    <link>
    http://localhost:4000</link>
    
      
      <item>
        <title>합성곱 신경망 기초 4(가중치 초기화, Weight Initialization)</title>
        
          <description>&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;CNN 강좌는 여러 절로 구성되어 있습니다. &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic&quot;&gt;합성곱 신경망 기초(CNN, Convolution Neural Network)&lt;/a&gt;&lt;/li&gt; &lt;!-- 확장자 X 시간 X 파일의 이름만 작성--&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-2&quot;&gt;합성곱 신경망 기초 2(역전파, Backpropagation)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-3&quot;&gt;합성곱 신경망 기초 3(배치정규화, Batch Normalization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-4&quot;&gt;합성곱 신경망 기초 4(가중치 초기화, Weight Initialization)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

</description>
        
        <pubDate>Mon, 17 Jan 2022 21:00:00 +0900</pubDate>
        <link>
        http://localhost:4000/cnn-basic-4</link>
        <guid isPermaLink="true">http://localhost:4000/cnn-basic-4</guid>
      </item>
      
    
      
      <item>
        <title>합성곱 신경망 기초 3(배치정규화, Batch Normalization)</title>
        
          <description>&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;CNN 강좌는 여러 절로 구성되어 있습니다. &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic&quot;&gt;합성곱 신경망 기초(CNN, Convolution Neural Network)&lt;/a&gt;&lt;/li&gt; &lt;!-- 확장자 X 시간 X 파일의 이름만 작성--&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-2&quot;&gt;합성곱 신경망 기초 2(역전파, Backpropagation)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-3&quot;&gt;합성곱 신경망 기초 3(배치정규화, Batch Normalization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-4&quot;&gt;합성곱 신경망 기초 4(가중치 초기화, Weight Initialization)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br /&gt;
그래디언트 손실(Vanishing Gradient)와 폭주(Exploding)문제를 해결할 수 있는 방법&lt;br /&gt;
“배치 정규화, 가중치 초기화”&lt;/p&gt;
&lt;h3 id=&quot;배치-정규화&quot;&gt;배치 정규화&lt;/h3&gt;
&lt;p&gt;깊은 신경망일 수록 같은 Input 이라도 가중치가 조금이라도 다르다면 완전히 다른 결과를 가져올 수 있다.&lt;br /&gt;
&lt;strong&gt;“각 층이 활성화를 적당히 퍼뜨리도록 강제로 해보자”&lt;/strong&gt;
&lt;img src=&quot;../../assets/built/images/cnn/22-01-18/1.jpeg&quot; alt=&quot;1&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;배치란? 신경망 학습시, 전체 데이터를 한 번에 학습시키지 않고, 조그만 단위로 분할해서 학습 시키는 것.&lt;/li&gt;
  &lt;li&gt;배치 정규화란? 배치 단위로 정규화 하는 것.&lt;/li&gt;
&lt;/ul&gt;

</description>
        
        <pubDate>Mon, 17 Jan 2022 21:00:00 +0900</pubDate>
        <link>
        http://localhost:4000/cnn-basic-3</link>
        <guid isPermaLink="true">http://localhost:4000/cnn-basic-3</guid>
      </item>
      
    
      
      <item>
        <title>합성곱 신경망 기초 2(CNN, 역전파 Backpropagation)</title>
        
          <description>&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;CNN 강좌는 여러 절로 구성되어 있습니다. &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic&quot;&gt;합성곱 신경망 기초(CNN, Convolution Neural Network)&lt;/a&gt;&lt;/li&gt; &lt;!-- 확장자 X 시간 X 파일의 이름만 작성--&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-2&quot;&gt;합성곱 신경망 기초 2(역전파, Backpropagation)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-3&quot;&gt;합성곱 신경망 기초 3(배치정규화, Batch Normalization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-4&quot;&gt;합성곱 신경망 기초 4(가중치 초기화, Weight Initialization)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        
        <pubDate>Mon, 17 Jan 2022 21:00:00 +0900</pubDate>
        <link>
        http://localhost:4000/cnn-basic-2</link>
        <guid isPermaLink="true">http://localhost:4000/cnn-basic-2</guid>
      </item>
      
    
      
      <item>
        <title>합성곱 신경망 기초(CNN, Convolution Neural Network)</title>
        
          <description>&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;CNN 강좌는 여러 절로 구성되어 있습니다. &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic&quot;&gt;합성곱 신경망 기초(CNN, Convolution Neural Network)&lt;/a&gt;&lt;/li&gt; &lt;!-- 확장자 X 시간 X 파일의 이름만 작성--&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-2&quot;&gt;합성곱 신경망 기초 2(역전파, Backpropagation)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-3&quot;&gt;합성곱 신경망 기초 3(배치정규화, Batch Normalization)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;./cnn-basic-4&quot;&gt;합성곱 신경망 기초 4(가중치 초기화, Weight Initialization)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        
        <pubDate>Sun, 16 Jan 2022 21:00:00 +0900</pubDate>
        <link>
        http://localhost:4000/cnn-basic</link>
        <guid isPermaLink="true">http://localhost:4000/cnn-basic</guid>
      </item>
      
    
      
      <item>
        <title>Java 강좌(1) - Java 기본</title>
        
          <description>&lt;p&gt;자바입니다.&lt;/p&gt;
</description>
        
        <pubDate>Mon, 10 Jan 2022 09:30:00 +0900</pubDate>
        <link>
        http://localhost:4000/java-basic</link>
        <guid isPermaLink="true">http://localhost:4000/java-basic</guid>
      </item>
      
    
  </channel>
</rss>
